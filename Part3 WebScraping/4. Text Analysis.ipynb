{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text Analysis 실습\n",
    "- **TF-IDF & Cosine similarity**을 이용하여 텍스트 간 유사도 계산하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "#### 1. 두 개의 영화 리뷰 텍스트 간 유사도 계산하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) The Shawshank Redemption (1994) & The Godfather (1972)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유사도 분석에 필요한 패키지를 불러온다\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scikit-learn - sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50241 57441\n"
     ]
    }
   ],
   "source": [
    "with open('shawshank.txt', 'r', encoding = 'utf-8') as f:  \n",
    "    doc1 = ''  # 리뷰 데이터를 담기 위한 String 변수 생성\n",
    "    lines = f.readlines()  # 영화 리뷰 파일의 모든 라인을 읽어와 리스트로 저장\n",
    "    for line in lines:  # for문을 통해 lines에 있는 모든 텍스트를 doc1에 이어 붙임\n",
    "        doc1 += line\n",
    "\n",
    "with open('godfather.txt', 'r', encoding= 'utf-8') as f: \n",
    "    doc2 = ''  # 리뷰 데이터를 담기 위한 String 변수 생성\n",
    "    lines = f.readlines()  # 영화 리뷰 파일의 모든 라인을 읽어와 리스트로 저장\n",
    "    for line in lines:  # for문을 통해 lines에 있는 모든 텍스트를 doc2에 이어 붙임\n",
    "        doc2 += line\n",
    "\n",
    "print(len(doc1),len(doc2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [doc1, doc2]  # doc1, doc2를 합쳐 corpus list를 생성\n",
    "# corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()  # TfidfVectorizer() 객체 변수 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit_transform()를 통해 corpus의 텍스트 데이터를 벡터화해 X에 저장하고 X를 dense한 matrix로 변환\n",
    "# raw counts have been normalized against document length, terms that are found across many docs are weighted down.\n",
    "\n",
    "# fit_transform에 corpus를 넣으면 행렬이 되고 todense함수를 적용\n",
    "X = vectorizer.fit_transform(corpus).todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# idf는 단어 빈도 횟수의 역수에 비례하는 함수\n",
    "- 흔한 단어면 그 값이 작고\n",
    "- 흔하지 않은 단어면 그 값이 크다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0071001  0.00332632 0.         ... 0.         0.00166316 0.        ]\n",
      " [0.00889703 0.         0.00138938 ... 0.00138938 0.         0.00138938]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>3266</th>\n",
       "      <th>3267</th>\n",
       "      <th>3268</th>\n",
       "      <th>3269</th>\n",
       "      <th>3270</th>\n",
       "      <th>3271</th>\n",
       "      <th>3272</th>\n",
       "      <th>3273</th>\n",
       "      <th>3274</th>\n",
       "      <th>3275</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.007100</td>\n",
       "      <td>0.003326</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001663</td>\n",
       "      <td>0.001663</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001663</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011834</td>\n",
       "      <td>0.001663</td>\n",
       "      <td>0.001183</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001663</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001663</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.008897</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001389</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001389</td>\n",
       "      <td>0.001389</td>\n",
       "      <td>0.001389</td>\n",
       "      <td>0.001389</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005558</td>\n",
       "      <td>0.001389</td>\n",
       "      <td>0.002966</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001977</td>\n",
       "      <td>0.001389</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001389</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 3276 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0         1         2         3         4         5         6     \\\n",
       "0  0.007100  0.003326  0.000000  0.001663  0.001663  0.000000  0.000000   \n",
       "1  0.008897  0.000000  0.001389  0.000000  0.000000  0.001389  0.001389   \n",
       "\n",
       "       7         8         9     ...      3266      3267      3268      3269  \\\n",
       "0  0.000000  0.000000  0.001663  ...  0.000000  0.000000  0.011834  0.001663   \n",
       "1  0.001389  0.001389  0.000000  ...  0.005558  0.001389  0.002966  0.000000   \n",
       "\n",
       "       3270      3271      3272      3273      3274      3275  \n",
       "0  0.001183  0.000000  0.001663  0.000000  0.001663  0.000000  \n",
       "1  0.001977  0.001389  0.000000  0.001389  0.000000  0.001389  \n",
       "\n",
       "[2 rows x 3276 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame(X)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.matrix'>\n",
      "(2, 3276)\n"
     ]
    }
   ],
   "source": [
    "print(type(X))\n",
    "print(X.shape) # 모양 확인 : 2행 3276열의 행렬 (각 행은 각 영화 리뷰 데이터의 word(열) 출현 빈도에 대한 dense matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between 'The Shawshank Redemption' and 'The Godfather':  [[0.9437827]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Similarity between 'The Shawshank Redemption' and 'The Godfather': \", cosine_similarity(X[0], X[1])) # 코사인 유사도"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 2) The Shawshank Redemption (1994) & Inception (2010)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between 'The Shawshank Redemption' and 'Inception':  [[0.19704257]]\n"
     ]
    }
   ],
   "source": [
    "with open('shawshank.txt', 'r', encoding = 'utf-8') as f: \n",
    "    doc1 = ''  # 리뷰 데이터를 담기 위한 String 변수 생성\n",
    "    lines = f.readlines()  # 영화 리뷰 파일의 모든 라인을 읽어와 리스트로 저장\n",
    "    for line in lines:  # for문을 통해 lines에 있는 모든 텍스트를 doc1에 이어 붙임\n",
    "        doc1 += line\n",
    "    \n",
    "with open('inception.txt', 'r', encoding= 'utf-8') as f:  \n",
    "    doc2 = ''  # 리뷰 데이터를 담기 위한 String 변수 생성\n",
    "    lines = f.readlines()  # 영화 리뷰 파일의 모든 라인을 읽어와 리스트로 저장\n",
    "    for line in lines:  # for문을 통해 lines에 있는 모든 텍스트를 doc2에 이어 붙임\n",
    "        doc2 += line\n",
    "    \n",
    "corpus = [doc1, doc2]  # doc1, doc2를 합쳐 corpus list를 생성\n",
    "vectorizer = TfidfVectorizer()  # TfidfVectorizer() 객체 변수 생성\n",
    "X = vectorizer.fit_transform(corpus).todense() # fit_transform()를 통해 corpus의 텍스트 데이터를 벡터화해 X에 저장하고 X를 dense한 matrix로 변환\n",
    "\n",
    "print(\"Similarity between 'The Shawshank Redemption' and 'Inception': \", cosine_similarity(X[0], X[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "#### 2. 여러 영화 리뷰 텍스트 간 유사도 계산하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('shawshank.txt', 'r', encoding = 'utf-8') as f: \n",
    "    doc1 = ''  # 리뷰 데이터를 담기 위한 String 변수 생성\n",
    "    lines = f.readlines()  # 영화 리뷰 파일의 모든 라인을 읽어와 리스트로 저장\n",
    "    for line in lines:  # for문을 통해 lines에 있는 모든 텍스트를 doc1에 이어 붙임\n",
    "        doc1 += line\n",
    "\n",
    "with open('godfather.txt', 'r', encoding= 'utf-8') as f:\n",
    "    doc2 = ''  # 리뷰 데이터를 담기 위한 String 변수 생성\n",
    "    lines = f.readlines()  # 영화 리뷰 파일의 모든 라인을 읽어와 리스트로 저장\n",
    "    for line in lines:  # for문을 통해 lines에 있는 모든 텍스트를 doc2에 이어 붙임\n",
    "        doc2 += line\n",
    "    \n",
    "with open('inception.txt', 'r', encoding= 'utf-8') as f: \n",
    "    doc3 = ''  # 리뷰 데이터를 담기 위한 String 변수 생성\n",
    "    lines = f.readlines()  # 영화 리뷰 파일의 모든 라인을 읽어와 리스트로 저장\n",
    "    for line in lines:  # for문을 통해 lines에 있는 모든 텍스트를 doc2에 이어 붙임\n",
    "        doc3 += line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [doc1, doc2, doc3]\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(corpus).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between 'The Shawshank Redemption' and 'The Godfather':  [[0.93484399]]\n",
      "Similarity between 'The Shawshank Redemption' and 'Inception':  [[0.18080469]]\n",
      "Similarity between 'The Godfather' and 'Inception':  [[0.16267018]]\n"
     ]
    }
   ],
   "source": [
    "# 영화 간 cosine similarity 계산\n",
    "print(\"Similarity between 'The Shawshank Redemption' and 'The Godfather': \", cosine_similarity(X[0], X[1]))\n",
    "print(\"Similarity between 'The Shawshank Redemption' and 'Inception': \", cosine_similarity(X[0], X[2]))\n",
    "print(\"Similarity between 'The Godfather' and 'Inception': \", cosine_similarity(X[1], X[2]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
