## Machine Learning, CNN, RNN



CNN의 문제점? 시간 오래 걸린다.

##### Kaggle에서 평가가 좋았던 핵심 알고리즘들

| Machin Learning                                           | Deep Learning                                                |
| --------------------------------------------------------- | ------------------------------------------------------------ |
| RandomForest(RF) -> XGBoost<br />계산속도가 빠르다.<br /> | Tensroflow <br />**Keras**<br />계산 속도가 느리다.<br />DNN, CNN, RNN |

예를 들면 XGBoost의 정확도가 95%일 때, Tensorflow(kears)를 쓸 때 이 보다 낮은 확률이 나오면 쓸 필요가 없다. Keras가 tensorflow 2.0에 정식으로 포함되었다. 1.x 후반 버전에서 이미 tf.keras를 사용할 수 있었다. 



1. 결측치 처리 방법? 인접값, 평균값, 제거, **예측**, 특정값을 채워넣는 방법이 있지만 선호되는 방법은 없다.  autoKeras, autoML 방법도 존재한다.

2. Keras

   ![img](https://mblogthumb-phinf.pstatic.net/MjAxNjExMjFfNDkg/MDAxNDc5Njg3MjE3Njkw.APzqHHzwreraTC4hPDz55jA2Z9x075EQ-06mkAfAbr8g.exGjuKLtKtyCpPYQUftOSydYNdc0vnBqewCPi2k7eOQg.PNG.gyrbsdl18/1.PNG?type=w2)

   ```python
   model=Sequential()
   model.add(Dense(4), input_dim=6) 
   model.add(Dense(3))
   model.add(Dense(1))
   ```

   Input Layer: 6 node

   Hidden Layer 1: 4 node

   Hidden Layer 2: 3 node

   Output Layer: 1 node

   **Deep Learning**

   layer의 깊이나 node의 개수를 조절하여 hidden layer의 층을 결정할 수 있다. 이 층은 데이터의 수에 비례하게 만들어 준다.



HyperParameter Tuning



#### Visual Studio Code 설치

1. google 에서 visual studio code 다운로드
2. 옵션에서 path 반드시 클릭해서 추가
3. python 찾아서 위에서 5개 설치(Python, VSCode, Extension Pack, Extended, Indent)
4. Korea를 찾아서 Korea Language Pack for Vi 설치
5. 폴더 안에 Study 폴더 keras 생성, VS 안에 keras 폴더 연결
6. `Ctrl+F5 `는 실행키, 줄 가운데에서 `Ctrl+C` 하고 다른 줄에 가면 모두 복사



Loss: loss function, Optimizer: Adam, Metrics: accuracy

Epoch: 학습 반복 횟수, Batch_size: 업데이트 하는데 필요한 데이터 갯수



### keras01_1.py

**회귀**



회귀모델에서의 평가 방법

- 회귀 모델에서는 accuracy를 사용하지 않고 rmse, rmae, mse, mae 등 다른 지표가 존재한다.

  MSE(Mean Squared Error)
  $$
  MSE=\frac{1}{n}\sum_{i=1}^{n}(y_{i}-\hat{y}_i)^2  \\
  y_{i}: 정답, \hat{y}_i : 예측값
  $$
  MAE(Mean Absolute Error)
  $$
  MAE=\frac{1}{n}\sum_{i=1}^{n}|y_{i}-\hat{y}_i|  \\
  y_{i}: 정답, \hat{y}_i : 예측값
  $$
  MSE와 MAE 모두 양수 값을 갖는다.

  

  RMSE(Root Mean Squared Error)
  $$
  RMSE=\sqrt{MSE}=
  \sqrt{\frac{1}{n}\sum_{i=1}^{n}(y_{i}-\hat{y}_i)^2}  \\
  y_{i}: 정답, \hat{y}_i : 예측값
  $$
  

  RMAE(Root Mean Absolute Error)
  $$
  RMAE=\sqrt{MAE}=\sqrt{\frac{1}{n}\sum_{i=1}^{n}|y_{i}-\hat{y}_i|}  \\
  y_{i}: 정답, \hat{y}_i : 예측값
  $$



총 데이터를 집어넣고 모두 계산했을 때가 1 epoch이고 1 epoch이 되어야 뉴런에 존재하는 가중치들을 변경하는데, batch size가 의미하는 것은 데이터셋을 batch_size만큼 계산하면 가중치를 업데이트를 한다.

batch_size가 작을수록 시간이 오래걸리지만, 대체로 정확도가 높아지는 경향이 있다고 한다. batch_size가 데이터셋의 숫자를 넘게되면 데이터 셋의 개수를 값으로 골라서 프로그램을 실행한다. batch_size가 크면 데이터셋을 모두 넣어서 계산하기 때문에 정확도가 낮아지는 경향이 있다. 

batch_size만큼 계산을 하면 가중치가 변하고 1 epoch만큼 되어야 MSE가 계산이 된다.

배치 사이즈의 기본 값은 **`batch_size` will default to 32**



- 데이터 정제는 매우 중요하다!

- 하이퍼파라미터 튜닝 - 1. model.add(Dense(#)), 2. metrics, 3. epoch, 4. batch_size 5. Layer 개수



Epoch: 모든 데이터 셋을 한 번 학습하는 횟수

Batch_size: Total number of training examples present in a single batch

![img](https://mblogthumb-phinf.pstatic.net/MjAxOTAxMjNfMjU4/MDAxNTQ4MjM1Nzg3NTA2.UtvnGsckZhLHOPPOBWH841IWsZFzNcgwZvYKi2nxImEg.CdtqIxOjWeBo4eNBD2pXu5uwYGa3ZVUr8WZvtldArtYg.PNG.qbxlvnf11/20190123_182720.png?type=w800)



### 

#### $y=WX+b$

회귀 모델의 머신(딥)러닝은 1차 함수 모델에서 W와 b를 계산하는 과정이다. 

W는 가중치 or weight라고 한다. b는 편향 or bias라고 한다.

원래 데이터를 수정해서는 안된다.

$y=ax^2+bx+c \\ y'=2ax+b=Wx+b$



### keras02_summary.py

```python
model.add(Dense(5, input_dim=1))
model.add(Dense(2))
model.add(Dense(3))
model.add(Dense(1))

model.summary()
```

sequential model에 대한 summary

```python
Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_1 (Dense)              (None, 5)                 10        
_________________________________________________________________
dense_2 (Dense)              (None, 2)                 12        
_________________________________________________________________
dense_3 (Dense)              (None, 3)                 9         
_________________________________________________________________
dense_4 (Dense)              (None, 1)                 4         
=================================================================
Total params: 35
Trainable params: 35
Non-trainable params: 0
    
bias!
```

