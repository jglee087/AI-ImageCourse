{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 불러오기\n",
    "train = pd.read_csv('./data/train.csv', index_col=0)\n",
    "test = pd.read_csv('./data/test.csv', index_col=0)\n",
    "sample_submission = pd.read_csv('./data/sample_submission.csv', index_col=0)\n",
    "\n",
    "# Train 데이터의 타입을 Sample_submission에 대응하는 가변수 형태로 변환\n",
    "column_number = {}\n",
    "for i, column in enumerate(sample_submission.columns):\n",
    "    column_number[column] = i\n",
    "    \n",
    "def to_number(x, dic):\n",
    "    return dic[x]\n",
    "\n",
    "train['type_num'] = train['type'].apply(lambda x : to_number(x, column_number))\n",
    "\n",
    "# 모델에 적용할 데이터 셋 준비 \n",
    "x = train.drop(columns=['type', 'type_num'], axis=1)\n",
    "y = train['type_num']\n",
    "\n",
    "x = x.drop(columns=['fiberID'], axis=1)\n",
    "test_x = test.drop(columns=['fiberID'],axis=1)\n",
    "\n",
    "x_name=x.columns\n",
    "col_name=x_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.array(x)\n",
    "y=np.array(y)\n",
    "test_x=np.array(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lab21/.local/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold, RandomizedSearchCV\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, train_size=0.9, shuffle=True ,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "\n",
    "# scaler1=StandardScaler()\n",
    "# #scaler1=RobustScaler()\n",
    "\n",
    "# scaler1.fit(x_train)\n",
    "# x_train=scaler1.transform(x_train)\n",
    "# x_test=scaler1.transform(x_test)\n",
    "\n",
    "# test_x =scaler1.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "\n",
    "# scaler1=RobustScaler()\n",
    "\n",
    "# scaler1.fit(x_train)\n",
    "# x_train=scaler1.transform(x_train)\n",
    "# x_test=scaler1.transform(x_test)\n",
    "\n",
    "#test_x =scaler1.transform(test_x)\n",
    "\n",
    "scaler2=StandardScaler()\n",
    "\n",
    "scaler2.fit(x_train)\n",
    "x_train=scaler2.transform(x_train)\n",
    "x_test=scaler2.transform(x_test)\n",
    "\n",
    "test_x =scaler2.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=x.astype('float32')\n",
    "test_x=test_x.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, BatchNormalization, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/lab21/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 64)                1344      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 19)                2451      \n",
      "=================================================================\n",
      "Total params: 276,051\n",
      "Trainable params: 275,795\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "\n",
    "model.add(Dense(64,activation='elu',input_dim=20)) # input dimension\n",
    "model.add(Dense(128,activation='elu'))\n",
    "model.add(Dense(256,activation='elu'))\n",
    "model.add(Dense(256,activation='elu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(256,activation='elu'))\n",
    "model.add(Dense(128))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('elu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(256,activation='elu'))\n",
    "model.add(Dense(128,activation='elu'))\n",
    "model.add(Dense(19,activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/lab21/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 159992 samples, validate on 19999 samples\n",
      "Epoch 1/90\n",
      " - 4s - loss: 0.8356 - acc: 0.7302 - val_loss: 0.6666 - val_acc: 0.7623\n",
      "Epoch 2/90\n",
      " - 4s - loss: 0.6571 - acc: 0.7794 - val_loss: 0.5871 - val_acc: 0.7979\n",
      "Epoch 3/90\n",
      " - 4s - loss: 0.6152 - acc: 0.7916 - val_loss: 0.5748 - val_acc: 0.7952\n",
      "Epoch 4/90\n",
      " - 4s - loss: 0.5889 - acc: 0.7994 - val_loss: 0.6082 - val_acc: 0.8026\n",
      "Epoch 5/90\n",
      " - 4s - loss: 0.5693 - acc: 0.8060 - val_loss: 0.7883 - val_acc: 0.7424\n",
      "Epoch 6/90\n",
      " - 4s - loss: 0.5588 - acc: 0.8092 - val_loss: 0.7535 - val_acc: 0.7157\n",
      "Epoch 7/90\n",
      " - 4s - loss: 0.5504 - acc: 0.8113 - val_loss: 0.6321 - val_acc: 0.7666\n",
      "Epoch 8/90\n",
      " - 4s - loss: 0.5371 - acc: 0.8171 - val_loss: 0.6838 - val_acc: 0.7706\n",
      "Epoch 9/90\n",
      " - 4s - loss: 0.5377 - acc: 0.8152 - val_loss: 0.5708 - val_acc: 0.8045\n",
      "Epoch 10/90\n",
      " - 4s - loss: 0.5315 - acc: 0.8185 - val_loss: 0.4609 - val_acc: 0.8421\n",
      "Epoch 11/90\n",
      " - 4s - loss: 0.5252 - acc: 0.8201 - val_loss: 0.6111 - val_acc: 0.7827\n",
      "Epoch 12/90\n",
      " - 4s - loss: 0.5181 - acc: 0.8220 - val_loss: 0.5762 - val_acc: 0.8030\n",
      "Epoch 13/90\n",
      " - 4s - loss: 0.5160 - acc: 0.8226 - val_loss: 0.5067 - val_acc: 0.8205\n",
      "Epoch 14/90\n",
      " - 4s - loss: 0.5142 - acc: 0.8238 - val_loss: 0.4781 - val_acc: 0.8323\n",
      "Epoch 15/90\n",
      " - 4s - loss: 0.5103 - acc: 0.8243 - val_loss: 0.8082 - val_acc: 0.7014\n",
      "Epoch 16/90\n",
      " - 4s - loss: 0.5048 - acc: 0.8273 - val_loss: 0.4813 - val_acc: 0.8352\n",
      "Epoch 17/90\n",
      " - 4s - loss: 0.5040 - acc: 0.8277 - val_loss: 0.5034 - val_acc: 0.8262\n",
      "Epoch 18/90\n",
      " - 4s - loss: 0.4987 - acc: 0.8297 - val_loss: 0.4968 - val_acc: 0.8293\n",
      "Epoch 19/90\n",
      " - 4s - loss: 0.5007 - acc: 0.8291 - val_loss: 0.5206 - val_acc: 0.8218\n",
      "Epoch 20/90\n",
      " - 4s - loss: 0.4948 - acc: 0.8305 - val_loss: 0.6349 - val_acc: 0.7632\n",
      "Epoch 21/90\n",
      " - 4s - loss: 0.4924 - acc: 0.8313 - val_loss: 0.4961 - val_acc: 0.8284\n",
      "Epoch 22/90\n",
      " - 4s - loss: 0.4896 - acc: 0.8323 - val_loss: 0.4431 - val_acc: 0.8499\n",
      "Epoch 23/90\n",
      " - 4s - loss: 0.4843 - acc: 0.8345 - val_loss: 0.4589 - val_acc: 0.8404\n",
      "Epoch 24/90\n",
      " - 4s - loss: 0.4858 - acc: 0.8329 - val_loss: 0.5393 - val_acc: 0.8008\n",
      "Epoch 25/90\n",
      " - 4s - loss: 0.4845 - acc: 0.8334 - val_loss: 0.5237 - val_acc: 0.8233\n",
      "Epoch 26/90\n",
      " - 4s - loss: 0.4785 - acc: 0.8352 - val_loss: 0.5162 - val_acc: 0.8230\n",
      "Epoch 27/90\n",
      " - 4s - loss: 0.4763 - acc: 0.8362 - val_loss: 0.4679 - val_acc: 0.8382\n",
      "Epoch 28/90\n",
      " - 4s - loss: 0.4743 - acc: 0.8363 - val_loss: 0.7135 - val_acc: 0.7395\n",
      "Epoch 29/90\n",
      " - 4s - loss: 0.4726 - acc: 0.8377 - val_loss: 0.4578 - val_acc: 0.8432\n",
      "Epoch 30/90\n",
      " - 4s - loss: 0.4691 - acc: 0.8384 - val_loss: 0.5154 - val_acc: 0.8071\n",
      "Epoch 31/90\n",
      " - 4s - loss: 0.4702 - acc: 0.8376 - val_loss: 0.4901 - val_acc: 0.8287\n",
      "Epoch 32/90\n",
      " - 4s - loss: 0.4692 - acc: 0.8378 - val_loss: 0.4777 - val_acc: 0.8321\n",
      "Epoch 33/90\n",
      " - 4s - loss: 0.4657 - acc: 0.8397 - val_loss: 0.4429 - val_acc: 0.8448\n",
      "Epoch 34/90\n",
      " - 4s - loss: 0.4626 - acc: 0.8396 - val_loss: 0.4871 - val_acc: 0.8309\n",
      "Epoch 35/90\n",
      " - 4s - loss: 0.4653 - acc: 0.8397 - val_loss: 0.7824 - val_acc: 0.6990\n",
      "Epoch 36/90\n",
      " - 4s - loss: 0.4619 - acc: 0.8410 - val_loss: 0.4410 - val_acc: 0.8492\n",
      "Epoch 37/90\n",
      " - 4s - loss: 0.4598 - acc: 0.8409 - val_loss: 0.4383 - val_acc: 0.8467\n",
      "Epoch 38/90\n",
      " - 4s - loss: 0.4603 - acc: 0.8420 - val_loss: 0.4380 - val_acc: 0.8495\n",
      "Epoch 39/90\n",
      " - 4s - loss: 0.4579 - acc: 0.8423 - val_loss: 0.4256 - val_acc: 0.8527\n",
      "Epoch 40/90\n",
      " - 4s - loss: 0.4588 - acc: 0.8419 - val_loss: 0.4431 - val_acc: 0.8444\n",
      "Epoch 41/90\n",
      " - 4s - loss: 0.4549 - acc: 0.8434 - val_loss: 0.4539 - val_acc: 0.8431\n",
      "Epoch 42/90\n",
      " - 4s - loss: 0.4523 - acc: 0.8438 - val_loss: 0.4554 - val_acc: 0.8408\n",
      "Epoch 43/90\n",
      " - 4s - loss: 0.4528 - acc: 0.8428 - val_loss: 0.4696 - val_acc: 0.8295\n",
      "Epoch 44/90\n",
      " - 4s - loss: 0.4532 - acc: 0.8432 - val_loss: 0.5398 - val_acc: 0.7996\n",
      "Epoch 45/90\n",
      " - 4s - loss: 0.4510 - acc: 0.8438 - val_loss: 0.4315 - val_acc: 0.8484\n",
      "Epoch 46/90\n",
      " - 4s - loss: 0.4489 - acc: 0.8446 - val_loss: 0.4277 - val_acc: 0.8482\n",
      "Epoch 47/90\n",
      " - 4s - loss: 0.4505 - acc: 0.8438 - val_loss: 0.4982 - val_acc: 0.8165\n",
      "Epoch 48/90\n",
      " - 4s - loss: 0.4481 - acc: 0.8451 - val_loss: 0.4221 - val_acc: 0.8511\n",
      "Epoch 49/90\n",
      " - 4s - loss: 0.4484 - acc: 0.8442 - val_loss: 0.4234 - val_acc: 0.8518\n",
      "Epoch 50/90\n",
      " - 4s - loss: 0.4471 - acc: 0.8452 - val_loss: 0.4244 - val_acc: 0.8548\n",
      "Epoch 51/90\n",
      " - 4s - loss: 0.4461 - acc: 0.8453 - val_loss: 0.4302 - val_acc: 0.8509\n",
      "Epoch 52/90\n",
      " - 4s - loss: 0.4469 - acc: 0.8450 - val_loss: 0.4172 - val_acc: 0.8533\n",
      "Epoch 53/90\n",
      " - 4s - loss: 0.4434 - acc: 0.8456 - val_loss: 0.4583 - val_acc: 0.8394\n",
      "Epoch 54/90\n",
      " - 4s - loss: 0.4429 - acc: 0.8463 - val_loss: 0.4828 - val_acc: 0.8360\n",
      "Epoch 55/90\n",
      " - 4s - loss: 0.4470 - acc: 0.8454 - val_loss: 0.4144 - val_acc: 0.8551\n",
      "Epoch 56/90\n",
      " - 4s - loss: 0.4416 - acc: 0.8474 - val_loss: 0.4371 - val_acc: 0.8428\n",
      "Epoch 57/90\n",
      " - 4s - loss: 0.4416 - acc: 0.8459 - val_loss: 0.4364 - val_acc: 0.8458\n",
      "Epoch 58/90\n",
      " - 4s - loss: 0.4426 - acc: 0.8463 - val_loss: 0.4166 - val_acc: 0.8516\n",
      "Epoch 59/90\n",
      " - 4s - loss: 0.4396 - acc: 0.8481 - val_loss: 0.4243 - val_acc: 0.8515\n",
      "Epoch 60/90\n",
      " - 4s - loss: 0.4405 - acc: 0.8474 - val_loss: 0.4504 - val_acc: 0.8453\n",
      "Epoch 61/90\n",
      " - 4s - loss: 0.4398 - acc: 0.8471 - val_loss: 0.4664 - val_acc: 0.8321\n",
      "Epoch 62/90\n",
      " - 4s - loss: 0.4378 - acc: 0.8483 - val_loss: 0.4188 - val_acc: 0.8546\n",
      "Epoch 63/90\n",
      " - 4s - loss: 0.4371 - acc: 0.8483 - val_loss: 0.4108 - val_acc: 0.8554\n",
      "Epoch 64/90\n",
      " - 4s - loss: 0.4359 - acc: 0.8481 - val_loss: 0.4989 - val_acc: 0.8350\n",
      "Epoch 65/90\n",
      " - 4s - loss: 0.4357 - acc: 0.8492 - val_loss: 0.4317 - val_acc: 0.8487\n",
      "Epoch 66/90\n",
      " - 4s - loss: 0.4340 - acc: 0.8489 - val_loss: 0.4293 - val_acc: 0.8489\n",
      "Epoch 67/90\n",
      " - 4s - loss: 0.4318 - acc: 0.8497 - val_loss: 0.5128 - val_acc: 0.8090\n",
      "Epoch 68/90\n",
      " - 4s - loss: 0.4347 - acc: 0.8490 - val_loss: 0.4187 - val_acc: 0.8524\n",
      "Epoch 69/90\n",
      " - 4s - loss: 0.4322 - acc: 0.8492 - val_loss: 0.4103 - val_acc: 0.8582\n",
      "Epoch 70/90\n",
      " - 4s - loss: 0.4324 - acc: 0.8495 - val_loss: 0.4351 - val_acc: 0.8471\n",
      "Epoch 71/90\n",
      " - 4s - loss: 0.4308 - acc: 0.8493 - val_loss: 0.4167 - val_acc: 0.8553\n",
      "Epoch 72/90\n",
      " - 4s - loss: 0.4302 - acc: 0.8500 - val_loss: 0.4264 - val_acc: 0.8481\n",
      "Epoch 73/90\n",
      " - 4s - loss: 0.4308 - acc: 0.8496 - val_loss: 0.4074 - val_acc: 0.8553\n",
      "Epoch 74/90\n",
      " - 4s - loss: 0.4283 - acc: 0.8506 - val_loss: 0.4047 - val_acc: 0.8582\n",
      "Epoch 75/90\n",
      " - 4s - loss: 0.4301 - acc: 0.8496 - val_loss: 0.5276 - val_acc: 0.8318\n",
      "Epoch 76/90\n",
      " - 4s - loss: 0.4274 - acc: 0.8513 - val_loss: 0.4525 - val_acc: 0.8427\n",
      "Epoch 77/90\n",
      " - 4s - loss: 0.4279 - acc: 0.8512 - val_loss: 0.5007 - val_acc: 0.8106\n",
      "Epoch 78/90\n",
      " - 4s - loss: 0.4280 - acc: 0.8510 - val_loss: 0.4353 - val_acc: 0.8449\n",
      "Epoch 79/90\n",
      " - 4s - loss: 0.4268 - acc: 0.8519 - val_loss: 0.3971 - val_acc: 0.8594\n",
      "Epoch 80/90\n",
      " - 4s - loss: 0.4256 - acc: 0.8513 - val_loss: 0.4334 - val_acc: 0.8484\n",
      "Epoch 81/90\n",
      " - 4s - loss: 0.4260 - acc: 0.8510 - val_loss: 0.5539 - val_acc: 0.8109\n",
      "Epoch 82/90\n",
      " - 4s - loss: 0.4252 - acc: 0.8514 - val_loss: 0.4109 - val_acc: 0.8561\n",
      "Epoch 83/90\n",
      " - 4s - loss: 0.4255 - acc: 0.8519 - val_loss: 0.4264 - val_acc: 0.8511\n",
      "Epoch 84/90\n",
      " - 4s - loss: 0.4247 - acc: 0.8527 - val_loss: 0.4551 - val_acc: 0.8364\n",
      "Epoch 85/90\n",
      " - 4s - loss: 0.4251 - acc: 0.8520 - val_loss: 0.4112 - val_acc: 0.8548\n",
      "Epoch 86/90\n",
      " - 4s - loss: 0.4219 - acc: 0.8517 - val_loss: 0.3980 - val_acc: 0.8573\n",
      "Epoch 87/90\n",
      " - 4s - loss: 0.4218 - acc: 0.8526 - val_loss: 0.4108 - val_acc: 0.8572\n",
      "Epoch 88/90\n",
      " - 4s - loss: 0.4230 - acc: 0.8519 - val_loss: 0.4190 - val_acc: 0.8531\n",
      "Epoch 89/90\n",
      " - 4s - loss: 0.4221 - acc: 0.8521 - val_loss: 0.3997 - val_acc: 0.8606\n",
      "Epoch 90/90\n",
      " - 4s - loss: 0.4224 - acc: 0.8520 - val_loss: 0.3953 - val_acc: 0.8586\n",
      "20000/20000 [==============================] - 0s 9us/step\n",
      "Loss: 0.39281251282691954 Accuracy: 0.86205\n"
     ]
    }
   ],
   "source": [
    "histo = model.fit(x_train, y_train, batch_size= 256, epochs=90, verbose=2, validation_split=1./9.)\n",
    "loss, acc = model.evaluate(x_test,y_test,batch_size= 256)\n",
    "print('Loss:',loss,'Accuracy:',acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict_proba(test_x)\n",
    "\n",
    "# 제출 파일 생성\n",
    "submission = pd.DataFrame(data=y_pred, columns=sample_submission.columns, index=sample_submission.index)\n",
    "submission.to_csv('./data/submission_data_10.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:aws_neuron_tensorflow_p36]",
   "language": "python",
   "name": "conda-env-aws_neuron_tensorflow_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
