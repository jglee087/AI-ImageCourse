{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install keras-swa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.ensemble import VotingClassifier, RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import lightgbm as lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Input, Dropout, Activation, BatchNormalization, GaussianNoise\n",
    "from keras.models import Model, load_model\n",
    "from keras import optimizers, callbacks\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint,Callback, EarlyStopping\n",
    "from keras import backend as K\n",
    "from swa.keras import SWA # swa\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./data/train.csv', index_col=0)\n",
    "test = pd.read_csv('./data/test.csv', index_col=0)\n",
    "sample_submission = pd.read_csv('./data/sample_submission.csv', index_col=0)\n",
    "\n",
    "# Train 데이터의 타입을 Sample_submission에 대응하는 가변수 형태로 변환\n",
    "column_number = {}\n",
    "for i, column in enumerate(sample_submission.columns):\n",
    "    column_number[column] = i\n",
    "    \n",
    "def to_number(x, dic):\n",
    "    return dic[x]\n",
    "\n",
    "train['type_num'] = train['type'].apply(lambda x : to_number(x, column_number))\n",
    "\n",
    "# 모델에 적용할 데이터 셋 준비 \n",
    "x = train.drop(columns=['type', 'type_num'], axis=1)\n",
    "y = train['type_num']\n",
    "\n",
    "x = x.drop(columns=['fiberID'], axis=1)\n",
    "test_x = test.drop(columns=['fiberID'],axis=1)\n",
    "\n",
    "x_name=x.columns\n",
    "col_name=x_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.array(x)\n",
    "y=np.array(y)\n",
    "test_x=np.array(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold, RandomizedSearchCV\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, stratify=y,\\\n",
    "                                                    train_size=0.9, shuffle=True ,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Activation\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "import tensorflow as tf\n",
    "\n",
    "class Gelu(Activation):\n",
    "    def __init__(self, activation, **kwargs):\n",
    "        super(Gelu, self).__init__(activation, **kwargs)\n",
    "        self.__name__='gelu'\n",
    "        \n",
    "def gelu(x):\n",
    "    return 0.5 * x * (1 + tf.tanh(np.sqrt(2 / np.pi) * (x + 0.044715 * np.power(x, 3))))\n",
    "\n",
    "get_custom_objects().update({'gelu': Gelu(gelu)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "\n",
    "# scaler1=RobustScaler()\n",
    "scaler2=StandardScaler()\n",
    "\n",
    "scaler2.fit(x_train)\n",
    "x_train=scaler2.transform(x_train)\n",
    "x_test=scaler2.transform(x_test)\n",
    "\n",
    "test_x =scaler2.transform(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr1 = 4.e-4 ; lr1_d = 4.e-5 \n",
    "lr2 = 3.e-4 ; lr2_d = 4.e-5\n",
    "lr3 = 2.e-4 ; lr3_d = 4.e-5\n",
    "\n",
    "drop1 = 0.2\n",
    "drop2 = 0.15\n",
    "drop3 = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-02-18 23:42:26.250557\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "start=datetime.datetime.now()\n",
    "print(start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Model\n",
    "- EarlyStop, CosineScheduler, CheckPoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_1(epochs=1200, drop=0.2, lr=lr1, lr_d=0):\n",
    "\n",
    "    inps= Input(shape = (20,))\n",
    "\n",
    "    la = Dense(128)(inps)\n",
    "    la = Activation(gelu)(la)\n",
    "    la = Dropout(drop1)(la)\n",
    "    \n",
    "    la = Dense(128)(la)\n",
    "    la = Activation(gelu)(la)\n",
    "    la = Dropout(drop1)(la)\n",
    "    \n",
    "    la = Dense(128)(la)\n",
    "    la = Activation(gelu)(la)\n",
    "    la = Dropout(drop1)(la)\n",
    "    \n",
    "    la = Dense(128)(la)\n",
    "    la = Activation(gelu)(la)\n",
    "    la = Dropout(drop1)(la)\n",
    "    \n",
    "    la = Dense(128)(la)\n",
    "    la = Activation(gelu)(la)\n",
    "    la = Dropout(drop1)(la)\n",
    "    \n",
    "    la = Dense(128)(la)\n",
    "    la = Activation(gelu)(la)\n",
    "    la = Dropout(drop1)(la)\n",
    "    \n",
    "    \n",
    "    outs=Dense(19,activation='softmax',name='output')(la)\n",
    "\n",
    "    models = Model(inputs=inps, outputs=outs)\n",
    "    models.summary()\n",
    "    models.compile(loss=\"sparse_categorical_crossentropy\", \\\n",
    "                   optimizer=Adam(lr=lr1,decay=lr1_d/epochs),metrics=['accuracy'])\n",
    "    return models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_2(epochs=1200, drop=0.2, lr=lr2, lr_d=0):\n",
    "\n",
    "    inps= Input(shape = (20,))\n",
    "\n",
    "    la = Dense(128)(inps)\n",
    "    la = Activation(gelu)(la)\n",
    "    la = Dropout(drop2)(la)\n",
    "\n",
    "    la = Dense(256)(la)\n",
    "    la = Activation(gelu)(la)\n",
    "    la = Dropout(drop2)(la)\n",
    "    \n",
    "    la = Dense(256)(la)\n",
    "    la = Activation(gelu)(la)\n",
    "    la = Dropout(drop2)(la)\n",
    "    \n",
    "    la = Dense(128)(la)\n",
    "    la = Activation(gelu)(la)\n",
    "    la = Dropout(drop2)(la)\n",
    "        \n",
    "    la = Dense(128)(la)\n",
    "    la = Activation(gelu)(la)\n",
    "    la = Dropout(drop2)(la)\n",
    "    \n",
    "    outs=Dense(19,activation='softmax',name='output')(la)\n",
    "\n",
    "    models = Model(inputs=inps, outputs=outs)\n",
    "    models.summary()\n",
    "    models.compile(loss=\"sparse_categorical_crossentropy\", \\\n",
    "                   optimizer=Adam(lr=lr2,decay=3.e-5/epochs),metrics=['accuracy'])\n",
    "    \n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_3(epochs=1200, drop=0.2, lr=lr3, lr_d=0):\n",
    "\n",
    "    inps= Input(shape = (20,))\n",
    "\n",
    "    la = Dense(128)(inps)\n",
    "    la = Activation(gelu)(la)\n",
    "    la = Dropout(drop3)(la)\n",
    "    \n",
    "    la = Dense(128)(la)\n",
    "    la = Activation(gelu)(la)\n",
    "    la = Dropout(drop3)(la)\n",
    "    \n",
    "    la = Dense(128)(la)\n",
    "    la = Activation(gelu)(la)\n",
    "    la = Dropout(drop3)(la)\n",
    "    \n",
    "    la = Dense(128)(la)\n",
    "    la = Activation(gelu)(la)\n",
    "    la = Dropout(drop3)(la)\n",
    "    \n",
    "    la = Dense(128)(la)\n",
    "    la = Activation(gelu)(la)\n",
    "    la = Dropout(drop3)(la)\n",
    "    \n",
    "    outs=Dense(19,activation='softmax',name='output')(la)\n",
    "\n",
    "    models = Model(inputs=inps, outputs=outs)\n",
    "    models.summary()\n",
    "    models.compile(loss=\"sparse_categorical_crossentropy\", \\\n",
    "                   optimizer=Adam(lr=lr3,decay=3.e-5/epochs),metrics=['accuracy'])\n",
    "    \n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_params = { 'validation_split': 1./9. }\n",
    "\n",
    "model_1a = KerasClassifier(build_fn = model_1, epochs = 1, drop=drop1, verbose=2, batch_size=256,\\\n",
    "                        lr=lr1, lr_d=lr1_d, **sk_params)\n",
    "\n",
    "model_1b = KerasClassifier(build_fn = model_1, epochs = 1, drop=drop2, verbose=0, batch_size=512,\\\n",
    "                        lr=lr1, lr_d=lr1_d, **sk_params)\n",
    "\n",
    "model_1c = KerasClassifier(build_fn = model_1, epochs = 1, drop=drop3, verbose=0, batch_size=512,\\\n",
    "                        lr=lr1, lr_d=lr1_d, **sk_params)\n",
    "\n",
    "model_2a = KerasClassifier(build_fn = model_2, epochs = 1, drop=drop1, verbose=2, batch_size=256,\\\n",
    "                        lr=lr2, lr_d=lr2_d, **sk_params)\n",
    "\n",
    "model_2b = KerasClassifier(build_fn = model_2, epochs = 1, drop=drop2, verbose=0, batch_size=512,\\\n",
    "                        lr=lr2, lr_d=lr2_d, **sk_params)\n",
    "\n",
    "model_2c = KerasClassifier(build_fn = model_2, epochs = 1, drop=drop3, verbose=0, batch_size=512,\\\n",
    "                        lr=lr2, lr_d=lr2_d, **sk_params)\n",
    "\n",
    "model_3a = KerasClassifier(build_fn = model_3, epochs = 1, drop=drop1, verbose=2, batch_size=256,\\\n",
    "                        lr=lr3, lr_d=lr3_d, **sk_params)\n",
    "\n",
    "model_3b = KerasClassifier(build_fn = model_3, epochs = 1, drop=drop2, verbose=0, batch_size=512,\\\n",
    "                        lr=lr3, lr_d=lr3_d, **sk_params)\n",
    "\n",
    "model_3c = KerasClassifier(build_fn = model_3, epochs = 1, drop=drop3, verbose=0, batch_size=512,\\\n",
    "                        lr=lr3, lr_d=lr3_d, **sk_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model= RandomForestClassifier()#(n_estimators=350,max_depth=8,bootstrap=True, random_state=42,\n",
    "                                #n_jobs=-1, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_model=lgbm.LGBMClassifier()#(n_estimators=350,max_depth=8,bootstrap=True, random_state=42,\\\n",
    "                              #learning_rate=0.02,n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbrt_model = GradientBoostingClassifier()#(n_estimators=350,max_depth=8, random_state=42, \\\n",
    "                                  #learning_rate=0.02,n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed = 7\n",
    "# np.random.seed(seed)\n",
    "# kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "# results = cross_val_score(model, X, y, cv=kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_clf = VotingClassifier(estimators = [ ('model0',rf_model), ('model1',lgbm_model), ('model2',gbrt_model),\n",
    "                                               ('model3', model_1a), ('model4', model_1b), ('model5', model_1c),\n",
    "                                               ('model6', model_2a), ('model7', model_2b), ('model8', model_2c),\n",
    "                                               ('model9', model_3a), ('model10', model_3b), ('model11', model_3c),],\n",
    "                                                 voting = 'soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jungg\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "ensemble_clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ensemble_clf.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end=datetime.datetime.now()\n",
    "print(\"걸린 시간:\", end-start)\n",
    "\n",
    "pred_test=ensemble_clf.predict_proba(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pred_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제출 파일 생성\n",
    "submission = pd.DataFrame(data=pred_test, columns=sample_submission.columns, index=sample_submission.index)\n",
    "submission.to_csv('./data/submission_data_KerasClassifier.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
