## Hyperparameter Optimization

딥러닝을 사용해 학습을 하다보면 신경망의 구조가 복잡하게 구성하다 보면 신경망의 하이퍼파라미터(hyperparameter)를 제대로 설정을 하지 못하면 좋은 성능을 만들어 낼 수 없다. 신경망을 통해 학습이라고 하는 것인 손실 함수를 최소화 시킨 가중치와 바이어스 값들을 찾아내는 것이다. 좋은 가중치와 바이어스를 찾기 위해 고 해서 숨겨진 층(hidden layer)와 노드(node)의 수를 많이 늘린다고 해서 좋은 성능을 보장하지 못한다. 따라서 하이퍼파라미터를 적절하게 설정해주는 것은 최상의 성능을 내기 위해 필요한 조건이다. 신경망에서 하이퍼파라미터는 사람들이 지정해 줄 수 있는 변수이다. 하이퍼파라미터들에 대해서는 나중에 자세히 설명하겠지만, 여기서 간단히 종류에 대해 살펴보면 batch size, epochs, loss function, optimizer, learning rate, activation function, dropout, regulaization, weight initialization 등이 존재한다. 이들을 적절하게 설정해주어 신경망을 학습하는 하이퍼파라미터 튜닝을 해주면 신경망에서 높은 성능을 만들어 낼 수 있다. 하지만 하이퍼파라미터를 튜닝하는 정답과 같은 공식이 존재하지 않고 경험이나 다양한 시도나 직관에 의해 결정된다. 그래도 하이퍼파라미터 최적화란 방법을 사용하여 하이퍼파라미터를 찾을 수 있다. 여기서 하이퍼파라미터의 최적값이란, 학습이 완료된 모델의 일반화 성능을 최고 수준으로 발휘하게 하는 하이퍼파라미터이다.

이런 하이퍼파라미터 최적화를 위한 방법을 보면 대략적으로 4가지 방법이 존재한다. 아래에서 그 방법에 대해 소개하겠다.



#### 1. Manual Search

설계자의 직관이나 이전의 경험에 기반하여, 몇 개의 하이퍼파라미터를 선택하고 이들을 사용하여 모델을 학습하고 그 결과들을 비교하여 그 중에 성능이 좋았던 하이퍼파라미터를 선택하는 방법이다. 예를 들면, 학습 진도율(learning rate)에 대한 최적화 작업을 수행한다고 하면, 먼저 임의 값을 대입하여 결과를 살핀 후 그 값으로부터 일정 정도 떨어진 값을 다시 적용하여 결과가 움직이는 방향으로 추정해보고, 이런 과정을 반복하여 좋은 과정을 추정한다. 어떤 “탐색 이론”을 사용하는가에 따라 시간이나 질이 달라질 수 있다. 값을 하나씩 대입해보며, 최적의 답을 찾거나 시간이 허용하는 선에서의 최적의 답을 찾으면 멈춘다.

하지만 이 방법에는 몇 가지 문제가 있다. 첫째로, 최적의 하이퍼파라미터를 찾을 때의 과정이 선택하는 값에 따라 모델의 정확도가 달라진다는 것이다. 딥러닝 모델의 최적 학습률을 찾기 위해 manual search를 수행을 할 것이다. 이 과정에는 시간 제한이 존재하기 때문에 몇 가지의 값을 넣고 그 중에 최적이라고 생각하는 것을 뽑겠지만 실제로 봤을 때 그 값이 꼭 최적이 될 것이라는 것을 보장할 수 없다.

두 번째로는 한 번에 여러 종류의 하이퍼파라미터들을 동시에 탐색할 경우 문제가 복잡해진다. 그리고 하이퍼파라미터들 중에는 서로 간의 상호 영양이 있는 것도 존재하기 때문에 둘 이상의 하이퍼파라미터들에 대한 탐색을 진행할 때는 단일 하이퍼파라미터를 적용할 경우에 달라지기 때문에 동시에 여러 개를 고려하기 어렵다.



#### 2. Grid Search

큰 관점에서는 manual search와 큰 차이가 없고 개념적으로도 비슷하다. 단, Grid search의 경우는 선험적인 지식을 활용하여 문제를 분석하고, 하이퍼파라미터의 범위를 정하기 때문에 상대적으로 체계적이라고 할 수 있다. 즉, 어떤 범위 안에서 일정한 간격으로 점을 정하고 그 점들에 대해 1개씩 차례로 실험을 해보면서 최적의 값을 찾은 후 다시 최고로 추정이 되는 점을 기준으로 세분화하여 최적값을 찾는 방법이다. 그래도 여전히 사람이 직접 정해줘야 해야 하지만 더 균등하고 전역적인 탐색이 가능하다. 그렇기 때문에 grid search는 ‘Parameter sweep’이라고도 불린다. manual search나 grid search를 할 때는 결과를 판정하기 위한 validation set가 필요하다. 하지만 하이퍼파라미터의 개수를 한 번에 여러 종류를 입력하면 탐색 시간이 기하급수적으로 증가한다는 단점이 있다.



####  3. Random Search

Grid search와 마찬가지로 선험적인 지식을 이용하여 하이퍼 파라미터의 범위를 정한다. 그 이후에 일정한 간격으로 탐색하는 대신에 무작위로 최적값을 찾는 작업을 진행을 한다는 점이 grid search와 다르다는 것이다.  Random search는 grid Search에 비해 불필요한 반복 수행 횟수를 대폭 줄이면서, 동시에 정해진 간격 사이에 위치한 값들에 대해서도 확률적으로 탐색이 가능하므로, 최적의 하이퍼파라미터 값을 더 빨리 찾을 수 있는 것으로 알려져 있습니다. 어찌 보면, grid search와 별 다를 것이 없어 보이지만, 하이퍼파라미터를 찾는 과정에서 시간이라는 ‘유한 자원’을 기반으로 해야 한다. 일정한 시간 안에 결과를 내야 하는 경우, Random search를 할 때 더 좋은 결과를 내는 경향이 있다고 한다.

####  4. Bayesian Optimization

앞서 살펴본 3가지 방식이 좀 효율적이지 못한 감이 있다. Bayesian optimization의 기본 원리가 prior knowledge를 활용하는데 있으므로, 현재까지의 실험 결과를 바탕으로 통계적인 모델을 만들고,그것을 바탕으로 다음 탐색을 해야 할 방향을 효과적으로 정하자는 것이 이 방법의 핵심이다. Bayesian optimization은 어느 입력값 x를 받는 미지의 목적 함수 f를 상정하여, 그 함숫값 $f(x)$를 최대로 만드는 최적해 $x^∗$를 찾는 것을 목적으로 한다. 보통은 목적 함수의 표현식을 명시적으로 알지 못하면서, 하나의 함숫값 $f(x)$를 계산하는 데 오랜 시간이 소요되는 경우를 가정한다. 그 중에 가능한 한 적은 수의 입력값 후보들에 대해서만 그 함숫값을 순차적으로 조사하고, $f(x)$를 최대로 만드는 최적해 $x^∗$를 빠르고 효과적으로 찾는 것이 주요 목표이다.

