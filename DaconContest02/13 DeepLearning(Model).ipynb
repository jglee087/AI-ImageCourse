{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 데이터 불러오기\n",
    "# train = pd.read_csv('./data/train.csv', index_col=0)\n",
    "# test = pd.read_csv('./data/test.csv', index_col=0)\n",
    "# sample_submission = pd.read_csv('./data/sample_submission.csv', index_col=0)\n",
    "\n",
    "# # Train 데이터의 타입을 Sample_submission에 대응하는 가변수 형태로 변환\n",
    "# column_number = {}\n",
    "# for i, column in enumerate(sample_submission.columns):\n",
    "#     column_number[column] = i\n",
    "    \n",
    "# def to_number(x, dic):\n",
    "#     return dic[x]\n",
    "\n",
    "# train['type_num'] = train['type'].apply(lambda x : to_number(x, column_number))\n",
    "\n",
    "# # 모델에 적용할 데이터 셋 준비 \n",
    "# x = train.drop(columns=['type', 'type_num'], axis=1)\n",
    "# y = train['type_num']\n",
    "\n",
    "# x = x.drop(columns=['fiberID'], axis=1)\n",
    "# test_x = test.drop(columns=['fiberID'],axis=1)\n",
    "\n",
    "# x_name=x.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('./data/sample_submission.csv', index_col=0)\n",
    "\n",
    "y = np.load('./data/y.npy')\n",
    "pred = np.load('./data/pred.npy')\n",
    "yy =pd.read_csv('./data/yy.csv',header=None)\n",
    "\n",
    "path='./data/column_name.txt'\n",
    "with open(path,'r')  as f:\n",
    "    col_name=f.read() \n",
    "\n",
    "x_name=col_name.split('\\n')\n",
    "try:\n",
    "    del(x_name[20])\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y=np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x=np.array(x)\n",
    "#test_x = np.array(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x = np.load('./data/x_percentile.npy')\n",
    "x = np.load('./data/x_try.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold, RandomizedSearchCV\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, stratify=y,train_size=0.8, shuffle=True ,random_state=0)\n",
    "#x_train, x_test, y_train, y_test = train_test_split(x,y, train_size=0.8, shuffle=True ,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6:2:2 비율"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "\n",
    "scaler1=StandardScaler()\n",
    "#scaler1=RobustScaler()\n",
    "scaler1.fit(x_train)\n",
    "x_train=scaler1.transform(x_train)\n",
    "x_test=scaler1.transform(x_test)\n",
    "\n",
    "scaler2=StandardScaler()\n",
    "#scaler2=RobustScaler()\n",
    "scaler2.fit(test_x)\n",
    "test_x =scaler2.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 현재까지 가장 안정적인 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model=Sequential()\n",
    "\n",
    "# model.add(Dense(64,activation='elu',input_dim=20)) # input dimension\n",
    "# model.add(Dense(128,activation='elu'))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(128,activation='elu'))\n",
    "# model.add(Dense(128,activation='elu'))\n",
    "# model.add(Dense(128,activation='elu'))\n",
    "# model.add(Dense(19,activation='softmax'))\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Input, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons =\n",
    "\n",
    "epochs =\n",
    "\n",
    "dropout_rate =\n",
    "\n",
    "batches =\n",
    "\n",
    "init_mode = ' '\n",
    "# init_mode = [ 'glorot_normal', 'he_normal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "\n",
    "model.add(Dense(64,activation='elu',input_dim=20)) # input dimension\n",
    "\n",
    "model.add(Dense(neurons,activation='elu',kernel_initializer=init_mode,\\\n",
    "           kernel_regularizer=regularizers.l2(0.01)))\n",
    "\n",
    "model.add(Dense(neurons,activation='elu',kernel_initializer=init_mode,\\\n",
    "           kernel_regularizer=regularizers.l2(0.01)))\n",
    "\n",
    "model.add(Dense(neurons,activation='elu',kernel_initializer=init_mode,\\\n",
    "           kernel_regularizer=regularizers.l2(0.01)))\n",
    "\n",
    "model.add(Dropout(dropout_rate))\n",
    "\n",
    "model.add(Dense(neurons,activation='elu',kernel_initializer=init_mode,\\\n",
    "           kernel_regularizer=regularizers.l2(0.01)))\n",
    "\n",
    "model.add(Dense(19,activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='loss', patience=20)\n",
    "\n",
    "hist= models.fit(x_train, y_train, batch_size= batches, epochs=epochs, verbose=2, validation_split=0.25, callbacks=[early_stopping] )\n",
    "loss, acc = models.evaluate(x_test,y_test,batch_size= batches)\n",
    "print('Loss:',loss,'Accuracy:',acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2 = models.predict_proba(test_x)\n",
    "# 제출 파일 생성\n",
    "submission2 = pd.DataFrame(data=y_pred2, columns=sample_submission.columns, index=sample_submission.index)\n",
    "submission2.to_csv('./data/submission_test_DL_0.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(hist.history.keys())\n",
    "\n",
    "fig, loss_ax = plt.subplots()\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "loss_ax.legend(loc='upper left')\n",
    "\n",
    "acc_ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "acc_ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "acc_ax.set_ylabel('accuracy')\n",
    "acc_ax.legend(loc='upper right')\n",
    "\n",
    "plt.savefig('res4.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
