{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install keras-rectified-adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "date='0222'\n",
    "filenumber='9'  #16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import regularizers\n",
    "from keras.utils import plot_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Input, Dropout, Activation, BatchNormalization, Concatenate, Conv1D, Flatten, MaxPooling1D\n",
    "from keras.models import Model, load_model\n",
    "from keras import optimizers, callbacks\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
    "from keras import backend as K\n",
    "from swa.keras import SWA\n",
    "from keras import initializers\n",
    "from keras_radam import RAdam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 불러오기\n",
    "train = pd.read_csv('./data/train.csv', index_col=0)\n",
    "#train_2 = pd.read_csv('./train_x_0.2_99.8.csv', index_col=0)\n",
    "\n",
    "test = pd.read_csv('./data/test.csv', index_col=0)\n",
    "sample_submission = pd.read_csv('./data/sample_submission.csv', index_col=0)\n",
    "\n",
    "# Train 데이터의 타입을 Sample_submission에 대응하는 가변수 형태로 변환\n",
    "column_number = {}\n",
    "for i, column in enumerate(sample_submission.columns):\n",
    "    column_number[column] = i\n",
    "    \n",
    "def to_number(x, dic):\n",
    "    return dic[x]\n",
    "\n",
    "train['type_num'] = train['type'].apply(lambda x : to_number(x, column_number))\n",
    "\n",
    "# 모델에 적용할 데이터 셋 준비 \n",
    "x = train.drop(columns=['type', 'type_num','fiberID'], axis=1)\n",
    "\n",
    "y = train['type_num']\n",
    "\n",
    "#x = train_2.drop(columns=['fiberID'], axis=1)\n",
    "\n",
    "test_x = test.drop(columns=['fiberID'],axis=1)\n",
    "\n",
    "x_name=x.columns\n",
    "col_name=x_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.array(x)\n",
    "y=np.array(y)\n",
    "test_x=np.array(test_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=x.astype('float32')\n",
    "test_x=test_x.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train_test_split\n",
    "# In[7]:\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, RandomizedSearchCV\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, ShuffleSplit\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x,y, stratify=y, \\\n",
    "                                                    train_size=0.6, shuffle=True ,random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "\n",
    "# scaler1=RobustScaler()\n",
    "scaler2=StandardScaler()\n",
    "\n",
    "scaler2.fit(x_train)\n",
    "x_train=scaler2.transform(x_train)\n",
    "x_val=scaler2.transform(x_val)\n",
    "\n",
    "test_x =scaler2.transform(test_x)\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_val = to_categorical(y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from keras.callbacks import Callback\n",
    "\n",
    "class LearningRateScheduler(Callback):\n",
    "    \"\"\"LearningRateScheduler\"\"\"\n",
    "    \n",
    "    def __init__(self, T_max, eta_max, eta_min, decay=10000,verbose=0):\n",
    "        super(LearningRateScheduler, self).__init__()\n",
    "        self.T_max = T_max\n",
    "        self.eta_max = eta_max\n",
    "        self.eta_min = eta_min\n",
    "        self.decay = decay\n",
    "        self.verbose = verbose\n",
    "        \n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        if not hasattr(self.model.optimizer, 'lr'):\n",
    "            raise ValueError('Optimizer must have a \"lr\" attribute.')\n",
    "\n",
    "        x1=1.\n",
    "        x2=1.-(2.*self.eta_min)/(self.eta_max+self.eta_min)\n",
    "        x3=x1+x2\n",
    "        \n",
    "        lr=self.eta_max/(x3)*(x1-x2*(np.cos(math.pi * np.mod(epoch,self.T_max) / (self.T_max) +np.pi))) * np.power(0.5,epoch/self.decay)\n",
    "\n",
    "        K.set_value(self.model.optimizer.lr, lr)\n",
    "        if self.verbose > 0:\n",
    "            print('\\nEpoch %05d: LearningRateSchedule setting learning '\n",
    "                  'rate to %s.' % (epoch + 1, lr))\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        logs['lr'] = K.get_value(self.model.optimizer.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Activation\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "import tensorflow as tf\n",
    "\n",
    "class Gelu(Activation):\n",
    "    def __init__(self, activation, **kwargs):\n",
    "        super(Gelu, self).__init__(activation, **kwargs)\n",
    "        self.__name__='gelu'\n",
    "        \n",
    "def gelu(x):\n",
    "    return 0.5 * x * (1 + tf.tanh(np.sqrt(2 / np.pi) * (x + 0.044715 * np.power(x, 3))))\n",
    "\n",
    "get_custom_objects().update({'gelu': Gelu(gelu)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 2.e-5\n",
    "# lr_d = 0\n",
    "patience =  40\n",
    "drop = 0.05\n",
    "nepoch = 240*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_max=60\n",
    "eta_max=2.0e-5\n",
    "eta_min=2.0e-5\n",
    "dec=0.000000001\n",
    "decay=nepoch/dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-02-29 11:07:06.447996\n"
     ]
    }
   ],
   "source": [
    "early_stop = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=patience)\n",
    "#learning_scheduler = LearningRateScheduler(T_max=T_max, eta_max=eta_max, eta_min=eta_min, decay=decay, verbose=1)\n",
    "\n",
    "import datetime\n",
    "start=datetime.datetime.now()\n",
    "print(start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x1_train=x_train.reshape(-1,20,1)\n",
    "x1_val= x_val.reshape(-1,20,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            (None, 20, 1)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 4, 128)       768         input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_43 (Dense)                (None, 128)          2688        input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 512)          0           conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 128)          0           dense_43[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_41 (Dense)                (None, 256)          131328      flatten_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_45 (Dense)                (None, 256)          33024       activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 256)          0           dense_41[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 256)          0           dense_45[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 256)          0           activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 256)          0           activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_40 (Dense)                (None, 128)          65664       flatten_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_42 (Dense)                (None, 128)          32896       dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_44 (Dense)                (None, 128)          16512       activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_46 (Dense)                (None, 128)          32896       dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 256)          0           dense_40[0][0]                   \n",
      "                                                                 dense_42[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 256)          0           dense_44[0][0]                   \n",
      "                                                                 dense_46[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 256)          0           concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 256)          0           concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 512)          0           activation_31[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_47 (Dense)                (None, 128)          65664       concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 128)          0           dense_47[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)            (None, 128)          0           activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_48 (Dense)                (None, 128)          16512       dropout_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 128)          0           dense_48[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)            (None, 128)          0           activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 19)           2451        dropout_20[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 400,403\n",
      "Trainable params: 400,403\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "inps1 = Input(shape = (20,1))\n",
    "inps2 = Input(shape = (20,))\n",
    "\n",
    "node = 128 # 128\n",
    "#############################################################\n",
    "\n",
    "la1 = Conv1D(128, 5, activation='relu',padding='same', strides=5)(inps1)\n",
    "#la1 = Conv1D(64, 5, activation='relu',padding='same')(la1)\n",
    "x1 = Flatten()(la1)\n",
    "\n",
    "for i in range(1):\n",
    "    xp = Dense(node)(x1)\n",
    "\n",
    "    x1 = Dense(node*2)(x1)\n",
    "    x1 = Activation('relu')(x1)\n",
    "    x1 = Dropout(0.20)(x1)\n",
    "\n",
    "    xq= Dense(node)(x1)\n",
    "\n",
    "    x1 = Concatenate()([xp,xq])\n",
    "    x1 = Activation('relu')(x1)\n",
    "\n",
    "\n",
    "##############################################################\n",
    "\n",
    "la2 = Dense(node)(inps2)\n",
    "x2  = Activation('relu')(la2)\n",
    "\n",
    "for i in range(1):\n",
    "    xp = Dense(node)(x2)\n",
    "\n",
    "    x2 = Dense(node*2)(x2)\n",
    "    x2 = Activation('relu')(x2)\n",
    "    x2 = Dropout(0.20)(x2)\n",
    "\n",
    "    xq= Dense(node)(x2)\n",
    "\n",
    "    x2 = Concatenate()([xp,xq])\n",
    "    x2 = Activation('relu')(x2)\n",
    "\n",
    "\n",
    "x4 = Concatenate()([x1,x2])\n",
    "\n",
    "x4 = Dense(node)(x4)\n",
    "x4 = Activation('relu')(x4)\n",
    "x4 = Dropout(drop)(x4)\n",
    "\n",
    "x4 = Dense(node)(x4)\n",
    "x4 = Activation('relu')(x4)\n",
    "x4 = Dropout(drop)(x4)\n",
    "\n",
    "outs=Dense(19,activation='softmax',name='output')(x4)\n",
    "\n",
    "models = Model(inputs=[inps1,inps2], outputs=outs)\n",
    "models.compile(RAdam(total_steps=500, warmup_proportion=0.1, min_lr=1e-5),loss='categorical_crossentropy' ,metrics=['accuracy'])\n",
    "\n",
    "models.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 119994 samples, validate on 79997 samples\n",
      "Epoch 1/960\n",
      " - 10s - loss: 2.9380 - accuracy: 0.2548 - val_loss: 2.9236 - val_accuracy: 0.3127\n",
      "Epoch 2/960\n",
      " - 10s - loss: 2.8857 - accuracy: 0.2616 - val_loss: 2.8086 - val_accuracy: 0.2484\n",
      "Epoch 3/960\n",
      " - 8s - loss: 2.6006 - accuracy: 0.2484 - val_loss: 2.3737 - val_accuracy: 0.2484\n",
      "Epoch 4/960\n",
      " - 9s - loss: 2.3187 - accuracy: 0.2572 - val_loss: 2.2605 - val_accuracy: 0.2605\n",
      "Epoch 5/960\n",
      " - 9s - loss: 2.2172 - accuracy: 0.3283 - val_loss: 2.1317 - val_accuracy: 0.3906\n",
      "Epoch 6/960\n",
      " - 8s - loss: 2.0640 - accuracy: 0.3875 - val_loss: 1.9598 - val_accuracy: 0.3921\n",
      "Epoch 7/960\n",
      " - 8s - loss: 1.9217 - accuracy: 0.3919 - val_loss: 1.8463 - val_accuracy: 0.3923\n",
      "Epoch 8/960\n",
      " - 9s - loss: 1.8348 - accuracy: 0.4017 - val_loss: 1.7731 - val_accuracy: 0.4114\n",
      "Epoch 9/960\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-66-7261eea0f997>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx1_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx1_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx_val\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mearly_stop\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#,swa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m#hist = models.fit([x1_train,x_train], y_train, batch_size= 256, epochs=nepoch, verbose=2, validation_data=[[x1_val,x_val], y_val], callbacks=[early_stop,learning_scheduler]) #,swa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx1_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m256\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Loss:'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Accuracy:'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0macc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3074\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3075\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 3076\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   3077\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3078\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "hist = models.fit([x1_train,x_train], y_train, batch_size= 256, epochs=nepoch, verbose=2, validation_data=[[x1_val,x_val], y_val], callbacks=[early_stop]) #,swa\n",
    "#hist = models.fit([x1_train,x_train], y_train, batch_size= 256, epochs=nepoch, verbose=2, validation_data=[[x1_val,x_val], y_val], callbacks=[early_stop,learning_scheduler]) #,swa\n",
    "\n",
    "loss, acc = models.evaluate([x1_test,x_test],y_test,batch_size= 256)\n",
    "print('Loss:',loss,'Accuracy:',acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end=datetime.datetime.now()\n",
    "print(end)\n",
    "print(\"걸린 시간:\", end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #y_pred = models.predict_proba(test_x)\n",
    "\n",
    "# test1_x=test_x.reshape(-1,20,1)\n",
    "# y_pred = models.predict([test1_x,test_x])\n",
    "\n",
    "# # 제출 파일 생성\n",
    "# submission = pd.DataFrame(data=y_pred, columns=sample_submission.columns, index=sample_submission.index)\n",
    "# submission.to_csv('/home/lab21/data/submission_no_fold_'+date+filenumber+'.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(hist.history.keys())\n",
    "\n",
    "fig, loss_ax = plt.subplots()\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "loss_ax.legend(loc='center')\n",
    "\n",
    "acc_ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "acc_ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "acc_ax.set_ylabel('accuracy')\n",
    "acc_ax.legend(loc='center right')\n",
    "\n",
    "plt.savefig('/home/lab21/data/submission_no_fold_'+date+filenumber+'_1.png')\n",
    "plt.show()\n",
    "\n",
    "fig, loss_ax = plt.subplots()\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "loss_ax.legend(loc='lower right')\n",
    "loss_ax.set_xlim(-1,1000)\n",
    "loss_ax.set_ylim(0.3,0.4)\n",
    "plt.savefig('/home/lab21/data/submission_no_fold_tr_'+date+filenumber+'_2.png')\n",
    "plt.show()\n",
    "\n",
    "fig, loss_ax = plt.subplots()\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "acc_ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "acc_ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "acc_ax.set_ylabel('accuracy')\n",
    "acc_ax.legend(loc='center right')\n",
    "acc_ax.set_xlim(100,1000)\n",
    "acc_ax.set_ylim(0.86,0.88)\n",
    "plt.savefig('/home/lab21/data/submission_no_fold_tr_'+date+filenumber+'_3.png')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(hist.history['lr'])\n",
    "plt.savefig('/home/lab21/data/submission_no_fold_tr_'+date+filenumber+'_lr.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
