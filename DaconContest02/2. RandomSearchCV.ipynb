{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Package Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split, KFold, RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Astronomical Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = pd.read_csv('./data/train.csv', index_col=0)\n",
    "# test = pd.read_csv('./data/test.csv', index_col=0)\n",
    "# sample_submission = pd.read_csv('./data/sample_submission.csv', index_col=0)\n",
    "\n",
    "# # Train 데이터의 타입을 Sample_submission에 대응하는 가변수 형태로 변환\n",
    "# column_number = {}\n",
    "# for i, column in enumerate(sample_submission.columns):\n",
    "#     column_number[column] = i\n",
    "    \n",
    "# def to_number(x, dic):\n",
    "#     return dic[x]\n",
    "\n",
    "# train['type_num'] = train['type'].apply(lambda x : to_number(x, column_number))\n",
    "\n",
    "# # 모델에 적용할 데이터 셋 준비 \n",
    "# x = train.drop(columns=['type', 'type_num'], axis=1)\n",
    "# y = train['type_num']\n",
    "\n",
    "# x = x.drop(columns=['fiberID'], axis=1)\n",
    "# test_x = test.drop(columns=['fiberID'],axis=1)\n",
    "\n",
    "# x_name=x.columns\n",
    "\n",
    "# x=np.array(x)\n",
    "# test_x = np.array(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Iris (for test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "iris_data =pd.read_csv(\"./iris2.csv\",encoding='utf-8')\n",
    "\n",
    "y=iris_data.loc[:,'Name']#.values\n",
    "x=iris_data.iloc[:,:-1]#.values\n",
    "\n",
    "x=x.values\n",
    "y=y.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Date Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = np.load('./data/x.npy')\n",
    "# y = np.load('./data/y.npy')\n",
    "# pred = np.load('./data/pred.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LabelEncoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "enc = LabelEncoder()\n",
    "enc.fit(y)\n",
    "y=enc.transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "#y=to_categorical(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y, train_size=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# StandardScaler, RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "\n",
    "# scaler1 = RobustScaler()\n",
    "# scaler1.fit(x_train)\n",
    "# x_train = scaler1.transform(x_train)\n",
    "# x_test = scaler1.transform(x_test)\n",
    "\n",
    "# scaler2 = RobustScaler()\n",
    "# scaler2.fit(test_x)\n",
    "# test_x = scaler2.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# scale=LabelEncoder()\n",
    "# scale.fit(y)\n",
    "# y=scale.transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model1 - RandomForest(RandomSearchCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold_cv = KFold(n_splits=5, shuffle=True)\n",
    "parameters =  {\"n_estimators\": [100,300,500], \"max_depth\":[4,8]}\n",
    "\n",
    "clf1=RandomForestClassifier()\n",
    "n_iter_search = 20\n",
    "\n",
    "clf1=RandomizedSearchCV( clf1, param_distributions=parameters, cv=kfold_cv, \\\n",
    "                        n_iter=n_iter_search,n_jobs=4)\n",
    "clf1.fit(x_train,y_train)\n",
    "\n",
    "y_pred=clf1.predict(x_test)\n",
    "\n",
    "print(\"acc\", accuracy_score(y_test, y_pred))\n",
    "print(clf1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 =RandomForestClassifier(**clf1.best_params_)\n",
    "#model1 =RandomForestClassifier()\n",
    "\n",
    "model1.fit(x_train, y_train)\n",
    "\n",
    "res=model1.score(x_test,y_test) \n",
    "print(res)\n",
    "\n",
    "#y_pred = model1.predict_proba(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    plt.bar(range((len(model1.feature_importances_))), model1.feature_importances_)\n",
    "\n",
    "except:\n",
    "    mid=len(x_name)//2\n",
    "\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    plt.bar(x_name[:mid], model1.feature_importances_[:mid])\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    plt.bar(x_name[mid:], model1.feature_importances_[mid:])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model2 - XGBClassifier(RandomSearchCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold_cv = KFold(n_splits=5, shuffle=True)\n",
    "parameters =  {\"n_estimators\": [200,400,600,800], \"max_depth\":[7,9,11], \\\n",
    "                \"lr\":[0.01,0.04,0.07,0.10], \"feature_fraction\":[0.6,0.9], \\\n",
    "                 \"num_iterations\":[500,800]}\n",
    "\n",
    "clf2= XGBClassifier()\n",
    "n_iter_search = 20\n",
    "\n",
    "clf2=RandomizedSearchCV( clf2, param_distributions=parameters, cv=kfold_cv, \\\n",
    "                        n_iter=n_iter_search)\n",
    "\n",
    "clf2.fit(x_train,y_train)\n",
    "\n",
    "y_pred=clf2.predict(x_test)\n",
    "\n",
    "print(\"acc\", accuracy_score(y_test, y_pred))\n",
    "print(clf2.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 =XGBClassifier(**clf2.best_params_)\n",
    "#model2 = XGBClassifier()\n",
    "\n",
    "eval_set = [(x_test, y_test)]\n",
    "model2.fit(x_train, y_train, eval_metric=\"mlogloss\", eval_set=eval_set, verbose=True,early_stopping_rounds=50)\n",
    "\n",
    "res=model2.score(x_test,y_test) \n",
    "print(res)\n",
    "\n",
    "#y_pred = model2.predict_proba(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    plt.bar(range((len(model2.feature_importances_))), model2.feature_importances_)\n",
    "\n",
    "except:\n",
    "    mid=len(x_name)//2\n",
    "\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    plt.bar(x_name[:mid], model2.feature_importances_[:mid])\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    plt.bar(x_name[mid:], model2.feature_importances_[mid:])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import plot_importance\n",
    "plot_importance(model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# thresholds = np.sort(model2.feature_importances_)\n",
    "# for thresh in thresholds:\n",
    "#     # select features using threshold\n",
    "#     selection = SelectFromModel(model2, threshold=thresh, prefit=True)\n",
    "#     select_x_train = selection.transform(x_train)\n",
    "#     # train model\n",
    "#     selection_model = XGBClassifier()\n",
    "#     selection_model.fit(select_x_train, y_train)\n",
    "#     # eval model\n",
    "#     select_x_test = selection.transform(x_test)\n",
    "#     y_predict = selection_model.predict(select_x_test)\n",
    "#     predictions = [round(value) for value in y_predict]\n",
    "#     accuracy = accuracy_score(y_test, predictions)\n",
    "#     print(\"Threshold=%.3f, n=%d, Accuracy: %.2f%%\" % (thresh, select_X_train.shape[1], accuracy*100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model3 - LGBMClassifier(RandomSearchCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold_cv = KFold(n_splits=5, shuffle=True)\n",
    "parameters =  {\"n_estimators\": [200,400,600,800], \"max_depth\":[7,9,11], \\\n",
    "                \"lr\":[0.01,0.04,0.07,0.10], \"feature_fraction\":[0.6,0.9], \\\n",
    "                 \"num_iterations\":[500,800]}\n",
    "\n",
    "clf3= LGBMClassifier()\n",
    "n_iter_search = 20\n",
    "\n",
    "clf3=RandomizedSearchCV( clf3, param_distributions=parameters, cv=kfold_cv, \\\n",
    "                        n_iter=n_iter_search,n_jobs=4)\n",
    "clf3.fit(x_train,y_train)\n",
    "\n",
    "y_pred=clf3.predict(x_test)\n",
    "\n",
    "print(\"acc\", accuracy_score(y_test, y_pred))\n",
    "print(clf3.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = LGBMClassifier(**clf3.best_params_)\n",
    "#model3 = LGBMClassifier()\n",
    "\n",
    "eval_set = [(x_test, y_test)]\n",
    "model3.fit(x_train, y_train, eval_metric=\"multi_logloss\", eval_set=eval_set, verbose=True,early_stopping_rounds=25)\n",
    "\n",
    "res=model3.score(x_test,y_test) \n",
    "print(res)\n",
    "\n",
    "#y_pred = model3.predict_proba(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    plt.bar(range((len(model3.feature_importances_))), model3.feature_importances_)\n",
    "\n",
    "except:\n",
    "    mid=len(x_name)//2\n",
    "\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    plt.bar(x_name[:mid], model3.feature_importances_[:mid])\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    plt.bar(x_name[mid:], model3.feature_importances_[mid:])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import plot_importance\n",
    "plot_importance(model3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
