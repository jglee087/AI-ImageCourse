## Under/Over Fitting



딥러닝 모델을 학습하는 과정은 학생 시절 시험 공부하는 것과 비슷한 점이 많다. 예를 들면, 모의고사를 보기 전에는 교과서와 문제집을 바탕으로 공부를 하고 시험 전에 기출문제를 풀면서 현재의 상황을 확인하는 방식으로 공부를 한다. 딥러닝 모델 역시 이와 같은 방식으로 학습을 하는 것으로 볼 수 있다. 딥러닝 모델의 학습에 사용되는 데이터는 교과서와 참고서이고 이는 딥러닝 모델에서는 **테스트 데이터**에 해당한다. 그리고 시험 성적은 **손실함수**에 해당한다. 중간에 점검하는 기출문제는 **검증 데이터**에 해당하고, 시험 당일에 주어진 시험은 **테스트 데이터**에 해당한다. 그러면 시험을 보고 나면 여러가지 유형이 존재한다.

1. 공부량이 부족하여 시험 성적이 좋지 않은 학생
2. 교과서와 참고서를 외우기만 하여 공부량에 비해 성적이 좋지 않은 학생
3. 개념에 대한 이해와 적당한 암기로 시험 성적이 좋은 학생

딥러닝 모델들도 **언더피팅(공부량이 부족하여 점수가 좋지 않은)**된 모델이 있고, **오버피팅(공부량은 많지만 점수가 좋지 않은)**된 모델이 있다. 딥러닝의 목표는 언더피팅도 아니고 오버피팅도 아닌 적절한 모델을 학습시키는 것이다. 이러한 목표는 한 번의 학습만으로 이루어지지 않고 계속 상황을 파악하고 적절한 피드백을 주어 다시 학습시키는 과정의 반복이다.



#### 딥러닝 모델과 함수

신경망 모델은 입력값이 주어지면 출력값이 나오는 역할을 하는 것이다. 마찬가지로 딥러닝 모델 역시도 입력값을 넣으면 출력값이 나온다. 주어진 가중치값에 따라 같은 입력값에 대한 출력값이 다르기 나온다. 딥러닝을 학습하는 목적은 손실함수를 가장 작게 만들어주는 가중치값을 정하는 것이다.



#### 학습용 데이터와 정답 함수

딥러닝 모델 학습의 목표는 입력값과 출력값(학습용 데이터와 레이블)의 관계를 찾는 것이다. 다시 말하면 "딥러닝 모델이 정답함수와 가장 비슷한 모양을 갖게 하는 가중치값들을 찾는 과정"이다. 손실함수는 정답함수와 딥러닝 모델이 얼마나 차이가 없는가를 나타내는 정량적인 수치이다. 이렇게 정답함수를 찾는데 사용되는 데이터들을 학습용 데이터라고 한다. 그리고 학습용 데이터와 테스트 데이터는 겹쳐서는 안된다.



**과대적합(overfitted)**된 신경망 모델은 학습용 데이터는 잘 예측하지만 정답 함수와 가깝지 않은 모델이고 **과소적합(underfitted)**된 모델은 학습용 데이터와 정답함수 모두를 예측하지 못하는 모델이다. 학습용 데이터와 정답함수 모두를 잘 예측하는 모델은 **적절한(fit)** 모델이라고 할 수 있다.



#### 정답함수와 테스트용 데이터

실제에서는 정답함수를 알 수 없다. 이럴 경우에는 테스트용 데이터는 정답함수를 알 수 없는  상황에서 가장 적절한 대안이다. 물론 이 경우에는 실제 현상을 잘 나타내는 테스트용 데이터라는 가정이 전제되었다. 정답함수를 테스트용 데이터로 대치해서 정답함수를 모르는 문제는 해결했지만, 여전히 큰 문제가 있다. 학습된 모델을 그래프로 시각화하여 언더피팅과 오버피팅을 판단했다. 하지만 입력 차원이 고차원이 되면 시각화할 수 없기 때문에 손실함수가 그 역할을 하게 된다.

딥러닝 모델의 학습을 진행할 때 손실함수 계산은 학습용 데이터로 한다. 학습이 올바른 방향으로 진행되고 있다면 학습용 데이터를 사용한 손실함수는 항상 작아진다. 하지만 테스트용 데이터를 이용하여 손실함수를 계산하게 되면 항상 작아진다고 보장할 수 없다. 왜냐면 딥러닝 모델을 학습시킬 때 최적화 문제는 학습용 데이터를 이용한 손실함수값을 작게 하는 것이기 때문이다. 학습용 데이터와 테스트용 데이터를 사용한 손실함수값들의 경향으로 언더/오버피팅 현상을 확인할 수 있다.



#### 언더피팅/오버피팅의 2가지 요인

언더피팅과 오버피팅을 만드는 요인은 크게 2가지가 있다. 
**첫째로,** capacity가 충분한 모델의 경우에 학습 반복 횟수에 따라 언더피팅이나 오버피팅이 될 수 있다. 이 경우에는 학습 반복 횟수를 적당하게 설정해야 가장 적절한 모델을 얻을 수 있다. 모델의 capacity란 모델이 나타낼 수 있는 복잡성을 말한다. 예를 들면, 신경망 모델에서는 레이어들의 개수나 노드 개수가 늘어날수록 더 많은 복잡성을 표현할 수 있다.
**둘째로,** 학습 반복 횟수는 적당하다는 전제로 모델의 capacity에 따라서도 언더피팅과 오버피팅이 결정된다. 모델이 너무 단순한 경우 아무리 학습을 해도 정확하지 않은 예측 모델을 만들 수 있다. 이 경우는 모델이 언더피팅된다. 하지만 모델의 capacity가 너무 큰 경우에는 학습용 데이터에 많이 치중하여 학습이 된다. 이런 경우 테스트용 데이터에서 손실함수가 증가하는 오버피팅된 모델을 얻게 된다.



### 언더피팅의 진단과 해결책

1) 학습 반복 횟수 재설정

입력값이 3차원 이상이 되면 오버피팅 또는 언더피팅을 시각화를 통해 알 수 없고, 학습용 데이터와 테스트용 데이터의 손실함수값을 직접 살펴봐야 한다. 학습 반복 횟수에 따라 언더피팅이 될 수 있다. 적절한 학습 반복 횟수를 주어야 손실 함수값이 수렴하는 정도가 되어야 적절한 모델을 만들 수 있다.

2) 학습률 재설정

학습률에 따라서도 언더피팅된 모델이 되거나 적절한 모델이 될 수 있다. 적절한 학습률을 설정해야 언더피팅 현상을 해결할 수 있다.

3) 모델 복잡도 증가

모델의 복잡도가 단순하면 언더피팅 현상이 발생할 가능성이 높다. 신경망 모델이 복잡하게 되면 언더피팅 현상을 해결할 수도 있다. 즉, 모델이 복잡하고 학습 관련 하이퍼 파라미터가 적절하게 잡혀있다면 언더피팅을 해결할 수 있다. 



#### 언더피팅 요약

언더피팅 현상을 겪게 되면 2가지를 반드시 체크해야 한다.

1.  주어진 모델과 데이터로 이루어진 손실함수의 최적화 문제를 수치 알고리즘이 잘 풀었는가?
2. 주어진 모델의 복잡도가 충분한가?

다른 언더피팅의 해결책 중에 학습 반복 횟수를 증가시키는 법과 학습률을 줄이는 방법은 최적화 문제를 푸는 수치 알고리즘 관련 파라미터를 조정한 것이다. 학습 반복 횟수와 학습률 외에도 미니 배치의 크기를 변경할 수도 있고, Adam 알고리즘 대신 RmsProp을 사용하여 해결할 수도 있다. 하지만 절대적인 법칙은 존재하지 않고 많은 학습 시도를 해야 하고, 많은 시도의 결과를 분석하여 현상을 올바르게 파악한 후 해결책을 선택해야 한다.

두 번째로 주어진 모델의 복잡도가 너무 단순하다면, 복잡도가 충분히 높은 모델로 변경해야 한다. 앞에서는 신경망 모델의 레이어를 추가하거나 노드 개수를 늘리는 방법으로 해결했다. 하지만 신경망 모델 자체가 주어진 문제를 푸는데 적절하지 않은 구조를 가지고 있을 수 있다. 이런 경우에는 CNN이나 RNN 등 수많은 딥러닝 모델을 고려하는 방법이 있다. 여기서 주의해야할 점은 모델 자체가 바뀌면 최적화 문제의 특성 자체가 변하므로 수치최적화 알고리즘의 파라미터들을 모두 재설정해야 한다.

마지막으로 언더피팅을 해결하는 방법은 결국 손실함수를 더 작게 만들어 주는 방법인데, 필요 이상으로 학습을 많이 시키면 오버피팅 현상이 나타난다. 많은 실험을 반복하여 언더피팅과 오버피팅 사이의 가장 적절한 딥러닝 모델을 찾는 것이 대부분의 딥러닝 모델을 이용한 실무와 연구의 패턴이다.



### 오버피팅의 진단과 해결책

1) 학습 반복 횟수 줄이기

학습을 단순히 많이 하게 되면 테스트 데이터에 대한 손실값이 줄어즐디만, 테스트 데이터에서는 손실값이 줄어들다 증가한다. 이 경우는 오버피팅이 된다. 이럴 경우에는 학습 반복 횟수를 줄여서 해결할 수 있다. Early stopping이라는 방법을 사용하면 하이퍼 파라미터 조절 없이 반복 횟수만 조절하여 오버피팅을 해결할 수 있다.



2) Regularization 함수 추가

오버피팅이 일어나는 이유는 최적화 관점에서 생각해보면 손실함수값이 필요 이상으로 작아진다는 것이다. 최적화 문제를 푸는 과정에서는 학습용 데이터만 사용하므로 테스트용 데이터가 반영이 안된 채 학습이 과하게 진행되면 오버피팅 문제가 생긴다. 그래서 손실함수값에 어떤 값을 추가하여 손실함수값이 너무 작아지지 않게 하는 것이 방법이다. 여기서 어떤 값을 바로 Regularization 함수라고 하고 2가지 방법이 존재한다.

- $L^2$ Regularization
- $L^1$ Regularization

3) 드롭아웃



##### 교차검증 데이터의 등장

교차검증(cross-validation)데이터를 설명할 차례이다. 일반적인 딥러닝 프로젝트를 진행할 때 2가지 경우가 있다. **첫 번째,** 정확한 테스트용 데이터가 있는 경우이다. 이 경우는 이번 장에서 다룬 방식으로 모델을 학습한 후 언더피팅과 오버피팅을 진단하고 그에 따른 적절한 해결 방법을 적용하면 된다. 

**두 번째는** 테스트용 데이터를 전혀 알 수 없는 경우이다. 이때는 언더피팅과 오버피팅의 판단을 위해 테스트용 데이터를 학습용 데이터에서 떼어내서 사용한다. 이런 경우에 교차검증 데이터라는 단어가 등장한다.

주어진 학습용 데이터 안에서 자체적으로 테스트 데이터를 만들어 언더피팅과 오버피팅을 확인해야 한다. 이때, 학습용 데이터에서 테스트 목적으로 떼어낸 부분을 교차검증 데이터라고 한다.



<참고>

(책) 딥러닝을 위한 최적화와 수치해석 