{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import pandas_profiling\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ = pd.read_csv('./data/train.csv',index_col=0)\n",
    "test_ = pd. read_csv('./data/test.csv',index_col=0)\n",
    "sample_submission = pd.read_csv('./data/sample_submission.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 설명\n",
    "\n",
    "-     대전지역에서 측정한 실내외 19곳의 센서데이터와, 주변 지역의 기상청 공공데이터를 semi-비식별화하여 제공합니다. \n",
    "-     센서는 온도를 측정하였습니다. \n",
    "-     모든 데이터는 시간 순으로 정렬 되어 있으며 10분 단위 데이터 입니다. \n",
    "-     예측 대상(target variable)은 Y18입니다. \n",
    "\n",
    "train.csv \n",
    "\n",
    "-     30일 간의 기상청 데이터 (X00 ~ X39) 및 센서데이터 (Y00~Y17)\n",
    "-     이후 3일 간의 기상청 데이터 (X00~X39) 및 센서데이터 (Y18)\n",
    "\n",
    "test.csv \n",
    "-     train.csv 기간 이후 80일 간의 기상청 데이터 (X00~X39)\n",
    "\n",
    "sample_submission.csv\n",
    "-     제출 양식 예시"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X00 X07 X28 X31 기온  \n",
    "X01 X06 X22 X27 기압  \n",
    "X02 X03 X18 X24 풍속  \n",
    "X04 X10 X21 X36 누적강수량  \n",
    "X05 X08 X09 X23 해면기압  \n",
    "X11 X14 X16 X19 누적일사량  \n",
    "X12, X20, X30, X37 습도\n",
    "X13 X15 X17 X25 풍향  \n",
    "\n",
    "Y00~17 센서측정온도  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=train_.copy()\n",
    "test=test_.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Y00 ~ Y17 >>> [0:4320]: Value, [4321:]: NaN, Y_index: [41:58]\n",
    "### Y18 >>> [0:4320]: NaN, [4321:]: Value, Y_index: [59]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp=0\n",
    "k=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(40,58):\n",
    "    if i != 46 | i != 47 | i != 52:\n",
    "        tp += train.iloc[0:4320,i]\n",
    "        k+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4752, 59)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.iloc[0:4320,58]=tp/k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X00</th>\n",
       "      <th>X01</th>\n",
       "      <th>X02</th>\n",
       "      <th>X03</th>\n",
       "      <th>X04</th>\n",
       "      <th>X05</th>\n",
       "      <th>X06</th>\n",
       "      <th>X07</th>\n",
       "      <th>X08</th>\n",
       "      <th>X09</th>\n",
       "      <th>...</th>\n",
       "      <th>Y09</th>\n",
       "      <th>Y10</th>\n",
       "      <th>Y11</th>\n",
       "      <th>Y12</th>\n",
       "      <th>Y13</th>\n",
       "      <th>Y14</th>\n",
       "      <th>Y15</th>\n",
       "      <th>Y16</th>\n",
       "      <th>Y17</th>\n",
       "      <th>Y18</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>9.7</td>\n",
       "      <td>988.8</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1009.3</td>\n",
       "      <td>989.6</td>\n",
       "      <td>12.2</td>\n",
       "      <td>1009.9</td>\n",
       "      <td>1009.8</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.9375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>9.3</td>\n",
       "      <td>988.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1009.3</td>\n",
       "      <td>989.6</td>\n",
       "      <td>12.1</td>\n",
       "      <td>1010.0</td>\n",
       "      <td>1009.9</td>\n",
       "      <td>...</td>\n",
       "      <td>6.5</td>\n",
       "      <td>7.5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.7500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>9.4</td>\n",
       "      <td>989.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1009.2</td>\n",
       "      <td>989.7</td>\n",
       "      <td>12.1</td>\n",
       "      <td>1010.1</td>\n",
       "      <td>1010.1</td>\n",
       "      <td>...</td>\n",
       "      <td>6.5</td>\n",
       "      <td>7.5</td>\n",
       "      <td>6.5</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>9.5</td>\n",
       "      <td>8.5</td>\n",
       "      <td>7.5</td>\n",
       "      <td>8.5</td>\n",
       "      <td>10.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>9.4</td>\n",
       "      <td>988.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1009.2</td>\n",
       "      <td>989.6</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1010.0</td>\n",
       "      <td>1010.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>7.5</td>\n",
       "      <td>8.5</td>\n",
       "      <td>10.3750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>9.2</td>\n",
       "      <td>988.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1009.2</td>\n",
       "      <td>989.7</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1010.1</td>\n",
       "      <td>1010.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>9.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>7.5</td>\n",
       "      <td>8.5</td>\n",
       "      <td>10.1875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    X00    X01  X02  X03  X04     X05    X06   X07     X08     X09  ...  Y09  \\\n",
       "id                                                                  ...        \n",
       "0   9.7  988.8  1.2  0.6  0.0  1009.3  989.6  12.2  1009.9  1009.8  ...  7.0   \n",
       "1   9.3  988.9  1.7  1.9  0.0  1009.3  989.6  12.1  1010.0  1009.9  ...  6.5   \n",
       "2   9.4  989.0  1.1  2.3  0.0  1009.2  989.7  12.1  1010.1  1010.1  ...  6.5   \n",
       "3   9.4  988.9  1.5  0.7  0.0  1009.2  989.6  12.0  1010.0  1010.0  ...  6.0   \n",
       "4   9.2  988.9  0.8  1.7  0.0  1009.2  989.7  12.0  1010.1  1010.0  ...  6.0   \n",
       "\n",
       "    Y10  Y11  Y12   Y13  Y14  Y15  Y16  Y17      Y18  \n",
       "id                                                    \n",
       "0   7.5  7.0  9.0  10.0  9.5  9.0  8.0  9.0  10.9375  \n",
       "1   7.5  7.0  8.5  10.0  9.5  9.0  7.5  9.0  10.7500  \n",
       "2   7.5  6.5  8.0   9.5  9.5  8.5  7.5  8.5  10.5000  \n",
       "3   7.0  6.0  8.0   9.5  9.0  8.5  7.5  8.5  10.3750  \n",
       "4   7.0  6.0  7.5   9.5  9.0  8.5  7.5  8.5  10.1875  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=train.iloc[:,1:40]\n",
    "y=train.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold, RandomizedSearchCV\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, ShuffleSplit\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, train_size=0.8, shuffle=False) #random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jungg\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  \n",
      "C:\\Users\\jungg\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "x_train.to_csv('x_train.csv')\n",
    "y_train.to_csv('y_train.csv')\n",
    "y_test.to_csv('y_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x=test.iloc[:,1:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "\n",
    "scaler2=StandardScaler()\n",
    "\n",
    "scaler2.fit(x_train)\n",
    "x_train=scaler2.transform(x_train)\n",
    "x_test=scaler2.transform(x_test)\n",
    "\n",
    "#test_x=scaler2.transform(test_x)\n",
    "\n",
    "# scaler1=StandardScaler()\n",
    "# scaler1.fit(y_train)\n",
    "# y_train=scaler1.transform(y_train)\n",
    "# y_test=scaler1.transform(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 23.7755648\ttotal: 39.4ms\tremaining: 2m 17s\n",
      "100:\tlearn: 9.2819702\ttotal: 2.99s\tremaining: 1m 40s\n",
      "200:\tlearn: 3.7870364\ttotal: 5.92s\tremaining: 1m 37s\n",
      "300:\tlearn: 1.7632262\ttotal: 8.77s\tremaining: 1m 33s\n",
      "400:\tlearn: 1.0544767\ttotal: 11.6s\tremaining: 1m 30s\n",
      "500:\tlearn: 0.7963412\ttotal: 14.5s\tremaining: 1m 26s\n",
      "600:\tlearn: 0.6796257\ttotal: 17.4s\tremaining: 1m 24s\n",
      "700:\tlearn: 0.6100803\ttotal: 20.7s\tremaining: 1m 22s\n",
      "800:\tlearn: 0.5596387\ttotal: 24.3s\tremaining: 1m 21s\n",
      "900:\tlearn: 0.5150573\ttotal: 27.9s\tremaining: 1m 20s\n",
      "1000:\tlearn: 0.4800518\ttotal: 31.7s\tremaining: 1m 19s\n",
      "1100:\tlearn: 0.4484667\ttotal: 34.9s\tremaining: 1m 16s\n",
      "1200:\tlearn: 0.4222831\ttotal: 38s\tremaining: 1m 12s\n",
      "1300:\tlearn: 0.3971251\ttotal: 41.3s\tremaining: 1m 9s\n",
      "1400:\tlearn: 0.3752887\ttotal: 45s\tremaining: 1m 7s\n",
      "1500:\tlearn: 0.3562499\ttotal: 48.4s\tremaining: 1m 4s\n",
      "1600:\tlearn: 0.3384791\ttotal: 51.9s\tremaining: 1m 1s\n",
      "1700:\tlearn: 0.3223612\ttotal: 55.4s\tremaining: 58.6s\n",
      "1800:\tlearn: 0.3083659\ttotal: 59.5s\tremaining: 56.2s\n",
      "1900:\tlearn: 0.2946218\ttotal: 1m 2s\tremaining: 53s\n",
      "2000:\tlearn: 0.2812608\ttotal: 1m 6s\tremaining: 49.9s\n",
      "2100:\tlearn: 0.2684067\ttotal: 1m 10s\tremaining: 46.8s\n",
      "2200:\tlearn: 0.2564257\ttotal: 1m 13s\tremaining: 43.6s\n",
      "2300:\tlearn: 0.2459990\ttotal: 1m 17s\tremaining: 40.6s\n",
      "2400:\tlearn: 0.2359726\ttotal: 1m 21s\tremaining: 37.5s\n",
      "2500:\tlearn: 0.2265341\ttotal: 1m 26s\tremaining: 34.4s\n",
      "2600:\tlearn: 0.2181154\ttotal: 1m 29s\tremaining: 31s\n",
      "2700:\tlearn: 0.2100160\ttotal: 1m 33s\tremaining: 27.7s\n",
      "2800:\tlearn: 0.2022162\ttotal: 1m 38s\tremaining: 24.7s\n",
      "2900:\tlearn: 0.1950998\ttotal: 1m 43s\tremaining: 21.4s\n",
      "3000:\tlearn: 0.1887635\ttotal: 1m 47s\tremaining: 17.8s\n",
      "3100:\tlearn: 0.1825994\ttotal: 1m 51s\tremaining: 14.3s\n",
      "3200:\tlearn: 0.1768829\ttotal: 1m 54s\tremaining: 10.7s\n",
      "3300:\tlearn: 0.1713893\ttotal: 1m 57s\tremaining: 7.1s\n",
      "3400:\tlearn: 0.1665815\ttotal: 2m\tremaining: 3.51s\n",
      "3499:\tlearn: 0.1619839\ttotal: 2m 3s\tremaining: 0us\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import lightgbm as lgbm\n",
    "import xgboost as xgb\n",
    "import catboost as cb\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "params={ 'max_depth':9, 'n_estimators':3500,  'learning_rate': 0.01, \\\n",
    "        'boost_from_average': False, 'subsample': 1}\n",
    "\n",
    "clf = cb.CatBoostRegressor(**params)\n",
    "model=clf.fit(x_train,y_train, verbose=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7677349006367142 5.600896754959119\n"
     ]
    }
   ],
   "source": [
    "print( r2_score(y_pred, y_test), mean_squared_error(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(data=pred, columns=sample_submission.columns, index=sample_submission.index)\n",
    "submission.to_csv('submission.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_train=np.array(x_train)\n",
    "y1_train=np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Input, Dropout, Activation, BatchNormalization, Concatenate, Conv1D, Flatten, MaxPooling1D\n",
    "from keras.models import Model, load_model\n",
    "from keras import optimizers, callbacks\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
    "from keras import backend as K\n",
    "from swa.keras import SWA\n",
    "from keras import initializers\n",
    "from keras_radam import RAdam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_13 (InputLayer)        (None, 39)                0         \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 120)               4800      \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 120)               480       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 120)               14520     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 120)               480       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 120)               14520     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 120)               480       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 120)               14520     \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 120)               480       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 120)               14520     \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 120)               480       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 1)                 121       \n",
      "=================================================================\n",
      "Total params: 65,401\n",
      "Trainable params: 64,201\n",
      "Non-trainable params: 1,200\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "inps = Input(shape = (39,))\n",
    "\n",
    "x= Dense(120)(inps)\n",
    "x= BatchNormalization()(x)\n",
    "x= Activation('elu')(x)\n",
    "\n",
    "x= Dense(120)(x)\n",
    "x= BatchNormalization()(x)\n",
    "x= Activation('elu')(x)\n",
    "\n",
    "x= Dense(120)(x)\n",
    "x= BatchNormalization()(x)\n",
    "x= Activation('elu')(x)\n",
    "\n",
    "x= Dense(120)(x)\n",
    "x= BatchNormalization()(x)\n",
    "x= Activation('elu')(x)\n",
    "\n",
    "x= Dense(120)(x)\n",
    "x= BatchNormalization()(x)\n",
    "x= Activation('elu')(x)\n",
    "\n",
    "outs=Dense(1,name='output')(x)\n",
    "\n",
    "models = Model(inputs=inps, outputs=outs)\n",
    "models.compile(loss='mse',optimizer=Adam(lr=1.e-5))\n",
    "models.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3801, 39), (3801,))"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1_train.shape,y1_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3420 samples, validate on 381 samples\n",
      "Epoch 1/100\n",
      " - 2s - loss: 575.1732 - val_loss: 547.7665\n",
      "Epoch 2/100\n",
      " - 1s - loss: 549.6251 - val_loss: 551.9979\n",
      "Epoch 3/100\n",
      " - 1s - loss: 536.7240 - val_loss: 554.8796\n",
      "Epoch 4/100\n",
      " - 1s - loss: 528.9959 - val_loss: 548.9240\n",
      "Epoch 5/100\n",
      " - 1s - loss: 522.5612 - val_loss: 542.6284\n",
      "Epoch 6/100\n",
      " - 1s - loss: 517.1278 - val_loss: 538.6050\n",
      "Epoch 7/100\n",
      " - 1s - loss: 511.8891 - val_loss: 526.0203\n",
      "Epoch 8/100\n",
      " - 1s - loss: 506.0818 - val_loss: 519.7293\n",
      "Epoch 9/100\n",
      " - 1s - loss: 501.5747 - val_loss: 513.1668\n",
      "Epoch 10/100\n",
      " - 1s - loss: 496.9877 - val_loss: 501.6527\n",
      "Epoch 11/100\n",
      " - 1s - loss: 492.4017 - val_loss: 490.1204\n",
      "Epoch 12/100\n",
      " - 1s - loss: 487.8273 - val_loss: 482.9963\n",
      "Epoch 13/100\n",
      " - 1s - loss: 483.3129 - val_loss: 475.3782\n",
      "Epoch 14/100\n",
      " - 1s - loss: 478.5331 - val_loss: 468.9411\n",
      "Epoch 15/100\n",
      " - 1s - loss: 474.0640 - val_loss: 461.9660\n",
      "Epoch 16/100\n",
      " - 1s - loss: 469.8086 - val_loss: 458.0519\n",
      "Epoch 17/100\n",
      " - 1s - loss: 465.7585 - val_loss: 451.3537\n",
      "Epoch 18/100\n",
      " - 1s - loss: 461.3118 - val_loss: 451.1623\n",
      "Epoch 19/100\n",
      " - 1s - loss: 457.3844 - val_loss: 441.7404\n",
      "Epoch 20/100\n",
      " - 1s - loss: 453.8571 - val_loss: 431.3075\n",
      "Epoch 21/100\n",
      " - 1s - loss: 449.8889 - val_loss: 435.3735\n",
      "Epoch 22/100\n",
      " - 1s - loss: 446.4518 - val_loss: 425.0689\n",
      "Epoch 23/100\n",
      " - 1s - loss: 442.1213 - val_loss: 421.7147\n",
      "Epoch 24/100\n",
      " - 1s - loss: 438.2552 - val_loss: 419.8245\n",
      "Epoch 25/100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-99-7f39539cbf00>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx1_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my1_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3074\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3075\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 3076\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   3077\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3078\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hist = models.fit(x1_train, y1_train, batch_size= 16, epochs=100, verbose=2, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
