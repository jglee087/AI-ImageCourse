{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 상태유지 스택 순환신경망 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import keras\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(signal_data, look_back=1):\n",
    "    dataX, dataY=[], []\n",
    "    for i in range(len(signal_data)-look_back):\n",
    "        dataX.append(signal_data[i:(i+look_back),0])\n",
    "        dataY.append(signal_data[i+look_back,0])\n",
    "    return np.array(dataX), np.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomHistory(keras.callbacks.Callback):\n",
    "    def init(self):\n",
    "        self.train_loss=[]\n",
    "        self.val_loss=[]\n",
    "    \n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.train_loss.append(logs.get('loss'))\n",
    "        self.val_loss.append(logs.get('val_loss'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ = pd.read_csv('../data/train.csv',index_col=0)\n",
    "test_ = pd. read_csv('../data/test.csv',index_col=0)\n",
    "sample_submission = pd.read_csv('../data/sample_submission.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "look_back=5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_data=train_['Y00'][0:4320,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4320, 1)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signal_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "#scaler=MinMaxScaler(feature_range=(0,1))\n",
    "scaler=StandardScaler()\n",
    "signal_data=scaler.fit_transform(signal_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "length=len(signal_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "len1=int(0.8*length)\n",
    "len2=int(0.1*length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = signal_data[:len1]\n",
    "val = signal_data[len1:len1+len2]\n",
    "test = signal_data[len1+len2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = create_dataset(train, look_back)\n",
    "x_val, y_val = create_dataset(val, look_back)\n",
    "x_test, y_test = create_dataset(test, look_back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
    "x_val=np.reshape(x_val, (x_val.shape[0], x_val.shape[1], 1))\n",
    "x_test=np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_11 (LSTM)               (1, 5, 16)                1152      \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (1, 5, 16)                0         \n",
      "_________________________________________________________________\n",
      "lstm_12 (LSTM)               (1, 5, 16)                2112      \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (1, 5, 16)                0         \n",
      "_________________________________________________________________\n",
      "lstm_13 (LSTM)               (1, 5, 16)                2112      \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (1, 5, 16)                0         \n",
      "_________________________________________________________________\n",
      "lstm_14 (LSTM)               (1, 16)                   2112      \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (1, 16)                   0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (1, 1)                    17        \n",
      "=================================================================\n",
      "Total params: 7,505\n",
      "Trainable params: 7,505\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model= Sequential()\n",
    "for i in range(3):\n",
    "    model.add(LSTM(16, batch_input_shape=(1, look_back,1) ,stateful=True, return_sequences=True, activation='tanh'))\n",
    "    model.add(Dropout(0.1))\n",
    "\n",
    "model.add(LSTM(16,  batch_input_shape=(1, look_back,1) , stateful=True, activation='tanh'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='MSE',optimizer='adam')\n",
    "custom_hist=CustomHistory()\n",
    "custom_hist.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Train on 3451 samples, validate on 427 samples\n",
      "Epoch 1/1\n",
      "3451/3451 [==============================] - 30s 9ms/step - loss: 0.1118 - val_loss: 0.0301\n",
      "1\n",
      "Train on 3451 samples, validate on 427 samples\n",
      "Epoch 1/1\n",
      "3451/3451 [==============================] - 30s 9ms/step - loss: 0.0552 - val_loss: 0.0211\n",
      "2\n",
      "Train on 3451 samples, validate on 427 samples\n",
      "Epoch 1/1\n",
      "3451/3451 [==============================] - 30s 9ms/step - loss: 0.0392 - val_loss: 0.0308\n",
      "3\n",
      "Train on 3451 samples, validate on 427 samples\n",
      "Epoch 1/1\n",
      "3451/3451 [==============================] - 30s 9ms/step - loss: 0.0367 - val_loss: 0.0101\n",
      "4\n",
      "Train on 3451 samples, validate on 427 samples\n",
      "Epoch 1/1\n",
      "3451/3451 [==============================] - 30s 9ms/step - loss: 0.0335 - val_loss: 0.0403\n",
      "5\n",
      "Train on 3451 samples, validate on 427 samples\n",
      "Epoch 1/1\n",
      "3451/3451 [==============================] - 30s 9ms/step - loss: 0.0331 - val_loss: 0.0154\n",
      "6\n",
      "Train on 3451 samples, validate on 427 samples\n",
      "Epoch 1/1\n",
      "3451/3451 [==============================] - 30s 9ms/step - loss: 0.0340 - val_loss: 0.0156\n",
      "7\n",
      "Train on 3451 samples, validate on 427 samples\n",
      "Epoch 1/1\n",
      "3451/3451 [==============================] - 31s 9ms/step - loss: 0.0270 - val_loss: 0.0299\n",
      "8\n",
      "Train on 3451 samples, validate on 427 samples\n",
      "Epoch 1/1\n",
      "3451/3451 [==============================] - 31s 9ms/step - loss: 0.0318 - val_loss: 0.0269\n",
      "9\n",
      "Train on 3451 samples, validate on 427 samples\n",
      "Epoch 1/1\n",
      "3451/3451 [==============================] - 31s 9ms/step - loss: 0.0259 - val_loss: 0.0229\n",
      "10\n",
      "Train on 3451 samples, validate on 427 samples\n",
      "Epoch 1/1\n",
      "3451/3451 [==============================] - 31s 9ms/step - loss: 0.0261 - val_loss: 0.0192\n",
      "11\n",
      "Train on 3451 samples, validate on 427 samples\n",
      "Epoch 1/1\n",
      "3451/3451 [==============================] - 31s 9ms/step - loss: 0.0283 - val_loss: 0.0129\n",
      "12\n",
      "Train on 3451 samples, validate on 427 samples\n",
      "Epoch 1/1\n",
      "3451/3451 [==============================] - 31s 9ms/step - loss: 0.0246 - val_loss: 0.0270\n",
      "13\n",
      "Train on 3451 samples, validate on 427 samples\n",
      "Epoch 1/1\n",
      "3451/3451 [==============================] - 31s 9ms/step - loss: 0.0272 - val_loss: 0.0379\n",
      "14\n",
      "Train on 3451 samples, validate on 427 samples\n",
      "Epoch 1/1\n",
      "2173/3451 [=================>............] - ETA: 10s - loss: 0.0289"
     ]
    }
   ],
   "source": [
    "for i in range(120):\n",
    "    print(i)\n",
    "    model.fit( x_train, y_train, epochs=1, batch_size=1, shuffle=False, callbacks=[custom_hist], validation_data=(x_val, y_val))\n",
    "    model.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainScore=model.evaluate(x_train, y_train, verbose=0,batch_size=1)\n",
    "model.reset_states()\n",
    "print('Train Score:', trainScore)\n",
    "\n",
    "ValScore=model.evaluate(x_val, y_val, verbose=0,batch_size=1)\n",
    "model.reset_states()\n",
    "print('Validation Score:', ValScore)\n",
    "\n",
    "testScore=model.evaluate(x_test, y_test, verbose=0,batch_size=1)\n",
    "model.reset_states()\n",
    "print('Test Score:', testScore)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "look_ahead=len(train_['Y00'])-len(train_['Y00'][0:4320])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "look_ahead=432+look_back\n",
    "\n",
    "xhat=x_test[0]\n",
    "predictions=np.zeros((look_ahead,1))\n",
    "\n",
    "for i in range(look_ahead):\n",
    "    prediction=model.predict(np.array([xhat]), batch_size=1)\n",
    "    predictions[i]=prediction\n",
    "    xhat=np.vstack([xhat[1:,],prediction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(12,5))\n",
    "# plt.plot(np.arange(look_ahead),predictions,'r',label='prediction')\n",
    "# plt.plot(np.arange(look_ahead),y_test[:412],label='test function')\n",
    "# plt.legend()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le1=np.arange(len(predictions))\n",
    "le2=np.arange(len(y_test))\n",
    "\n",
    "plt.plot(le1,predictions,'r',label='prediction')\n",
    "plt.plot(le2,y_test,label='test function')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:aws_neuron_tensorflow_p36]",
   "language": "python",
   "name": "conda-env-aws_neuron_tensorflow_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
